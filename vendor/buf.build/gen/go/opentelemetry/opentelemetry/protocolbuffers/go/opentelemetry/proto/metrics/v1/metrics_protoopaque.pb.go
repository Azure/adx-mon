// Copyright 2019, OpenTelemetry Authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.11
// 	protoc        (unknown)
// source: opentelemetry/proto/metrics/v1/metrics.proto

//go:build protoopaque

package metricsv1

import (
	v11 "buf.build/gen/go/opentelemetry/opentelemetry/protocolbuffers/go/opentelemetry/proto/common/v1"
	v1 "buf.build/gen/go/opentelemetry/opentelemetry/protocolbuffers/go/opentelemetry/proto/resource/v1"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// AggregationTemporality defines how a metric aggregator reports aggregated
// values. It describes how those values relate to the time interval over
// which they are aggregated.
type AggregationTemporality int32

const (
	// UNSPECIFIED is the default AggregationTemporality, it MUST not be used.
	AggregationTemporality_AGGREGATION_TEMPORALITY_UNSPECIFIED AggregationTemporality = 0
	// DELTA is an AggregationTemporality for a metric aggregator which reports
	// changes since last report time. Successive metrics contain aggregation of
	// values from continuous and non-overlapping intervals.
	//
	// The values for a DELTA metric are based only on the time interval
	// associated with one measurement cycle. There is no dependency on
	// previous measurements like is the case for CUMULATIVE metrics.
	//
	// For example, consider a system measuring the number of requests that
	// it receives and reports the sum of these requests every second as a
	// DELTA metric:
	//
	//  1. The system starts receiving at time=t_0.
	//  2. A request is received, the system measures 1 request.
	//  3. A request is received, the system measures 1 request.
	//  4. A request is received, the system measures 1 request.
	//  5. The 1 second collection cycle ends. A metric is exported for the
	//     number of requests received over the interval of time t_0 to
	//     t_0+1 with a value of 3.
	//  6. A request is received, the system measures 1 request.
	//  7. A request is received, the system measures 1 request.
	//  8. The 1 second collection cycle ends. A metric is exported for the
	//     number of requests received over the interval of time t_0+1 to
	//     t_0+2 with a value of 2.
	AggregationTemporality_AGGREGATION_TEMPORALITY_DELTA AggregationTemporality = 1
	// CUMULATIVE is an AggregationTemporality for a metric aggregator which
	// reports changes since a fixed start time. This means that current values
	// of a CUMULATIVE metric depend on all previous measurements since the
	// start time. Because of this, the sender is required to retain this state
	// in some form. If this state is lost or invalidated, the CUMULATIVE metric
	// values MUST be reset and a new fixed start time following the last
	// reported measurement time sent MUST be used.
	//
	// For example, consider a system measuring the number of requests that
	// it receives and reports the sum of these requests every second as a
	// CUMULATIVE metric:
	//
	//  1. The system starts receiving at time=t_0.
	//  2. A request is received, the system measures 1 request.
	//  3. A request is received, the system measures 1 request.
	//  4. A request is received, the system measures 1 request.
	//  5. The 1 second collection cycle ends. A metric is exported for the
	//     number of requests received over the interval of time t_0 to
	//     t_0+1 with a value of 3.
	//  6. A request is received, the system measures 1 request.
	//  7. A request is received, the system measures 1 request.
	//  8. The 1 second collection cycle ends. A metric is exported for the
	//     number of requests received over the interval of time t_0 to
	//     t_0+2 with a value of 5.
	//  9. The system experiences a fault and loses state.
	//  10. The system recovers and resumes receiving at time=t_1.
	//  11. A request is received, the system measures 1 request.
	//  12. The 1 second collection cycle ends. A metric is exported for the
	//     number of requests received over the interval of time t_1 to
	//     t_0+1 with a value of 1.
	//
	// Note: Even though, when reporting changes since last report time, using
	// CUMULATIVE is valid, it is not recommended. This may cause problems for
	// systems that do not use start_time to determine when the aggregation
	// value was reset (e.g. Prometheus).
	AggregationTemporality_AGGREGATION_TEMPORALITY_CUMULATIVE AggregationTemporality = 2
)

// Enum value maps for AggregationTemporality.
var (
	AggregationTemporality_name = map[int32]string{
		0: "AGGREGATION_TEMPORALITY_UNSPECIFIED",
		1: "AGGREGATION_TEMPORALITY_DELTA",
		2: "AGGREGATION_TEMPORALITY_CUMULATIVE",
	}
	AggregationTemporality_value = map[string]int32{
		"AGGREGATION_TEMPORALITY_UNSPECIFIED": 0,
		"AGGREGATION_TEMPORALITY_DELTA":       1,
		"AGGREGATION_TEMPORALITY_CUMULATIVE":  2,
	}
)

func (x AggregationTemporality) Enum() *AggregationTemporality {
	p := new(AggregationTemporality)
	*p = x
	return p
}

func (x AggregationTemporality) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (AggregationTemporality) Descriptor() protoreflect.EnumDescriptor {
	return file_opentelemetry_proto_metrics_v1_metrics_proto_enumTypes[0].Descriptor()
}

func (AggregationTemporality) Type() protoreflect.EnumType {
	return &file_opentelemetry_proto_metrics_v1_metrics_proto_enumTypes[0]
}

func (x AggregationTemporality) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// DataPointFlags is defined as a protobuf 'uint32' type and is to be used as a
// bit-field representing 32 distinct boolean flags.  Each flag defined in this
// enum is a bit-mask.  To test the presence of a single flag in the flags of
// a data point, for example, use an expression like:
//
//	(point.flags & DATA_POINT_FLAGS_NO_RECORDED_VALUE_MASK) == DATA_POINT_FLAGS_NO_RECORDED_VALUE_MASK
type DataPointFlags int32

const (
	// The zero value for the enum. Should not be used for comparisons.
	// Instead use bitwise "and" with the appropriate mask as shown above.
	DataPointFlags_DATA_POINT_FLAGS_DO_NOT_USE DataPointFlags = 0
	// This DataPoint is valid but has no recorded value.  This value
	// SHOULD be used to reflect explicitly missing data in a series, as
	// for an equivalent to the Prometheus "staleness marker".
	DataPointFlags_DATA_POINT_FLAGS_NO_RECORDED_VALUE_MASK DataPointFlags = 1
)

// Enum value maps for DataPointFlags.
var (
	DataPointFlags_name = map[int32]string{
		0: "DATA_POINT_FLAGS_DO_NOT_USE",
		1: "DATA_POINT_FLAGS_NO_RECORDED_VALUE_MASK",
	}
	DataPointFlags_value = map[string]int32{
		"DATA_POINT_FLAGS_DO_NOT_USE":             0,
		"DATA_POINT_FLAGS_NO_RECORDED_VALUE_MASK": 1,
	}
)

func (x DataPointFlags) Enum() *DataPointFlags {
	p := new(DataPointFlags)
	*p = x
	return p
}

func (x DataPointFlags) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (DataPointFlags) Descriptor() protoreflect.EnumDescriptor {
	return file_opentelemetry_proto_metrics_v1_metrics_proto_enumTypes[1].Descriptor()
}

func (DataPointFlags) Type() protoreflect.EnumType {
	return &file_opentelemetry_proto_metrics_v1_metrics_proto_enumTypes[1]
}

func (x DataPointFlags) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// MetricsData represents the metrics data that can be stored in a persistent
// storage, OR can be embedded by other protocols that transfer OTLP metrics
// data but do not implement the OTLP protocol.
//
// MetricsData
// └─── ResourceMetrics
//
//	├── Resource
//	├── SchemaURL
//	└── ScopeMetrics
//	   ├── Scope
//	   ├── SchemaURL
//	   └── Metric
//	      ├── Name
//	      ├── Description
//	      ├── Unit
//	      └── data
//	         ├── Gauge
//	         ├── Sum
//	         ├── Histogram
//	         ├── ExponentialHistogram
//	         └── Summary
//
// The main difference between this message and collector protocol is that
// in this message there will not be any "control" or "metadata" specific to
// OTLP protocol.
//
// When new fields are added into this message, the OTLP request MUST be updated
// as well.
type MetricsData struct {
	state                      protoimpl.MessageState `protogen:"opaque.v1"`
	xxx_hidden_ResourceMetrics *[]*ResourceMetrics    `protobuf:"bytes,1,rep,name=resource_metrics,json=resourceMetrics,proto3"`
	unknownFields              protoimpl.UnknownFields
	sizeCache                  protoimpl.SizeCache
}

func (x *MetricsData) Reset() {
	*x = MetricsData{}
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *MetricsData) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MetricsData) ProtoMessage() {}

func (x *MetricsData) ProtoReflect() protoreflect.Message {
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *MetricsData) GetResourceMetrics() []*ResourceMetrics {
	if x != nil {
		if x.xxx_hidden_ResourceMetrics != nil {
			return *x.xxx_hidden_ResourceMetrics
		}
	}
	return nil
}

func (x *MetricsData) SetResourceMetrics(v []*ResourceMetrics) {
	x.xxx_hidden_ResourceMetrics = &v
}

type MetricsData_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// An array of ResourceMetrics.
	// For data coming from a single resource this array will typically contain
	// one element. Intermediary nodes that receive data from multiple origins
	// typically batch the data before forwarding further and in that case this
	// array will contain multiple elements.
	ResourceMetrics []*ResourceMetrics
}

func (b0 MetricsData_builder) Build() *MetricsData {
	m0 := &MetricsData{}
	b, x := &b0, m0
	_, _ = b, x
	x.xxx_hidden_ResourceMetrics = &b.ResourceMetrics
	return m0
}

// A collection of ScopeMetrics from a Resource.
type ResourceMetrics struct {
	state                   protoimpl.MessageState `protogen:"opaque.v1"`
	xxx_hidden_Resource     *v1.Resource           `protobuf:"bytes,1,opt,name=resource,proto3"`
	xxx_hidden_ScopeMetrics *[]*ScopeMetrics       `protobuf:"bytes,2,rep,name=scope_metrics,json=scopeMetrics,proto3"`
	xxx_hidden_SchemaUrl    string                 `protobuf:"bytes,3,opt,name=schema_url,json=schemaUrl,proto3"`
	unknownFields           protoimpl.UnknownFields
	sizeCache               protoimpl.SizeCache
}

func (x *ResourceMetrics) Reset() {
	*x = ResourceMetrics{}
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ResourceMetrics) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ResourceMetrics) ProtoMessage() {}

func (x *ResourceMetrics) ProtoReflect() protoreflect.Message {
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *ResourceMetrics) GetResource() *v1.Resource {
	if x != nil {
		return x.xxx_hidden_Resource
	}
	return nil
}

func (x *ResourceMetrics) GetScopeMetrics() []*ScopeMetrics {
	if x != nil {
		if x.xxx_hidden_ScopeMetrics != nil {
			return *x.xxx_hidden_ScopeMetrics
		}
	}
	return nil
}

func (x *ResourceMetrics) GetSchemaUrl() string {
	if x != nil {
		return x.xxx_hidden_SchemaUrl
	}
	return ""
}

func (x *ResourceMetrics) SetResource(v *v1.Resource) {
	x.xxx_hidden_Resource = v
}

func (x *ResourceMetrics) SetScopeMetrics(v []*ScopeMetrics) {
	x.xxx_hidden_ScopeMetrics = &v
}

func (x *ResourceMetrics) SetSchemaUrl(v string) {
	x.xxx_hidden_SchemaUrl = v
}

func (x *ResourceMetrics) HasResource() bool {
	if x == nil {
		return false
	}
	return x.xxx_hidden_Resource != nil
}

func (x *ResourceMetrics) ClearResource() {
	x.xxx_hidden_Resource = nil
}

type ResourceMetrics_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The resource for the metrics in this message.
	// If this field is not set then no resource info is known.
	Resource *v1.Resource
	// A list of metrics that originate from a resource.
	ScopeMetrics []*ScopeMetrics
	// The Schema URL, if known. This is the identifier of the Schema that the resource data
	// is recorded in. Notably, the last part of the URL path is the version number of the
	// schema: http[s]://server[:port]/path/<version>. To learn more about Schema URL see
	// https://opentelemetry.io/docs/specs/otel/schemas/#schema-url
	// This schema_url applies to the data in the "resource" field. It does not apply
	// to the data in the "scope_metrics" field which have their own schema_url field.
	SchemaUrl string
}

func (b0 ResourceMetrics_builder) Build() *ResourceMetrics {
	m0 := &ResourceMetrics{}
	b, x := &b0, m0
	_, _ = b, x
	x.xxx_hidden_Resource = b.Resource
	x.xxx_hidden_ScopeMetrics = &b.ScopeMetrics
	x.xxx_hidden_SchemaUrl = b.SchemaUrl
	return m0
}

// A collection of Metrics produced by an Scope.
type ScopeMetrics struct {
	state                protoimpl.MessageState    `protogen:"opaque.v1"`
	xxx_hidden_Scope     *v11.InstrumentationScope `protobuf:"bytes,1,opt,name=scope,proto3"`
	xxx_hidden_Metrics   *[]*Metric                `protobuf:"bytes,2,rep,name=metrics,proto3"`
	xxx_hidden_SchemaUrl string                    `protobuf:"bytes,3,opt,name=schema_url,json=schemaUrl,proto3"`
	unknownFields        protoimpl.UnknownFields
	sizeCache            protoimpl.SizeCache
}

func (x *ScopeMetrics) Reset() {
	*x = ScopeMetrics{}
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ScopeMetrics) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ScopeMetrics) ProtoMessage() {}

func (x *ScopeMetrics) ProtoReflect() protoreflect.Message {
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *ScopeMetrics) GetScope() *v11.InstrumentationScope {
	if x != nil {
		return x.xxx_hidden_Scope
	}
	return nil
}

func (x *ScopeMetrics) GetMetrics() []*Metric {
	if x != nil {
		if x.xxx_hidden_Metrics != nil {
			return *x.xxx_hidden_Metrics
		}
	}
	return nil
}

func (x *ScopeMetrics) GetSchemaUrl() string {
	if x != nil {
		return x.xxx_hidden_SchemaUrl
	}
	return ""
}

func (x *ScopeMetrics) SetScope(v *v11.InstrumentationScope) {
	x.xxx_hidden_Scope = v
}

func (x *ScopeMetrics) SetMetrics(v []*Metric) {
	x.xxx_hidden_Metrics = &v
}

func (x *ScopeMetrics) SetSchemaUrl(v string) {
	x.xxx_hidden_SchemaUrl = v
}

func (x *ScopeMetrics) HasScope() bool {
	if x == nil {
		return false
	}
	return x.xxx_hidden_Scope != nil
}

func (x *ScopeMetrics) ClearScope() {
	x.xxx_hidden_Scope = nil
}

type ScopeMetrics_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The instrumentation scope information for the metrics in this message.
	// Semantically when InstrumentationScope isn't set, it is equivalent with
	// an empty instrumentation scope name (unknown).
	Scope *v11.InstrumentationScope
	// A list of metrics that originate from an instrumentation library.
	Metrics []*Metric
	// The Schema URL, if known. This is the identifier of the Schema that the metric data
	// is recorded in. Notably, the last part of the URL path is the version number of the
	// schema: http[s]://server[:port]/path/<version>. To learn more about Schema URL see
	// https://opentelemetry.io/docs/specs/otel/schemas/#schema-url
	// This schema_url applies to the data in the "scope" field and all metrics in the
	// "metrics" field.
	SchemaUrl string
}

func (b0 ScopeMetrics_builder) Build() *ScopeMetrics {
	m0 := &ScopeMetrics{}
	b, x := &b0, m0
	_, _ = b, x
	x.xxx_hidden_Scope = b.Scope
	x.xxx_hidden_Metrics = &b.Metrics
	x.xxx_hidden_SchemaUrl = b.SchemaUrl
	return m0
}

// Defines a Metric which has one or more timeseries.  The following is a
// brief summary of the Metric data model.  For more details, see:
//
//	https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/metrics/data-model.md
//
// The data model and relation between entities is shown in the
// diagram below. Here, "DataPoint" is the term used to refer to any
// one of the specific data point value types, and "points" is the term used
// to refer to any one of the lists of points contained in the Metric.
//
//   - Metric is composed of a metadata and data.
//
//   - Metadata part contains a name, description, unit.
//
//   - Data is one of the possible types (Sum, Gauge, Histogram, Summary).
//
//   - DataPoint contains timestamps, attributes, and one of the possible value type
//     fields.
//
//     Metric
//     +------------+
//     |name        |
//     |description |
//     |unit        |     +------------------------------------+
//     |data        |---> |Gauge, Sum, Histogram, Summary, ... |
//     +------------+     +------------------------------------+
//
//     Data [One of Gauge, Sum, Histogram, Summary, ...]
//     +-----------+
//     |...        |  // Metadata about the Data.
//     |points     |--+
//     +-----------+  |
//     |      +---------------------------+
//     |      |DataPoint 1                |
//     v      |+------+------+   +------+ |
//     +-----+   ||label |label |...|label | |
//     |  1  |-->||value1|value2|...|valueN| |
//     +-----+   |+------+------+   +------+ |
//     |  .  |   |+-----+                    |
//     |  .  |   ||value|                    |
//     |  .  |   |+-----+                    |
//     |  .  |   +---------------------------+
//     |  .  |                   .
//     |  .  |                   .
//     |  .  |                   .
//     |  .  |   +---------------------------+
//     |  .  |   |DataPoint M                |
//     +-----+   |+------+------+   +------+ |
//     |  M  |-->||label |label |...|label | |
//     +-----+   ||value1|value2|...|valueN| |
//     |+------+------+   +------+ |
//     |+-----+                    |
//     ||value|                    |
//     |+-----+                    |
//     +---------------------------+
//
// Each distinct type of DataPoint represents the output of a specific
// aggregation function, the result of applying the DataPoint's
// associated function of to one or more measurements.
//
// All DataPoint types have three common fields:
//   - Attributes includes key-value pairs associated with the data point
//   - TimeUnixNano is required, set to the end time of the aggregation
//   - StartTimeUnixNano is optional, but strongly encouraged for DataPoints
//     having an AggregationTemporality field, as discussed below.
//
// Both TimeUnixNano and StartTimeUnixNano values are expressed as
// UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.
//
// # TimeUnixNano
//
// This field is required, having consistent interpretation across
// DataPoint types.  TimeUnixNano is the moment corresponding to when
// the data point's aggregate value was captured.
//
// Data points with the 0 value for TimeUnixNano SHOULD be rejected
// by consumers.
//
// # StartTimeUnixNano
//
// StartTimeUnixNano in general allows detecting when a sequence of
// observations is unbroken.  This field indicates to consumers the
// start time for points with cumulative and delta
// AggregationTemporality, and it should be included whenever possible
// to support correct rate calculation.  Although it may be omitted
// when the start time is truly unknown, setting StartTimeUnixNano is
// strongly encouraged.
type Metric struct {
	state                  protoimpl.MessageState `protogen:"opaque.v1"`
	xxx_hidden_Name        string                 `protobuf:"bytes,1,opt,name=name,proto3"`
	xxx_hidden_Description string                 `protobuf:"bytes,2,opt,name=description,proto3"`
	xxx_hidden_Unit        string                 `protobuf:"bytes,3,opt,name=unit,proto3"`
	xxx_hidden_Data        isMetric_Data          `protobuf_oneof:"data"`
	xxx_hidden_Metadata    *[]*v11.KeyValue       `protobuf:"bytes,12,rep,name=metadata,proto3"`
	unknownFields          protoimpl.UnknownFields
	sizeCache              protoimpl.SizeCache
}

func (x *Metric) Reset() {
	*x = Metric{}
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Metric) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Metric) ProtoMessage() {}

func (x *Metric) ProtoReflect() protoreflect.Message {
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *Metric) GetName() string {
	if x != nil {
		return x.xxx_hidden_Name
	}
	return ""
}

func (x *Metric) GetDescription() string {
	if x != nil {
		return x.xxx_hidden_Description
	}
	return ""
}

func (x *Metric) GetUnit() string {
	if x != nil {
		return x.xxx_hidden_Unit
	}
	return ""
}

func (x *Metric) GetGauge() *Gauge {
	if x != nil {
		if x, ok := x.xxx_hidden_Data.(*metric_Gauge); ok {
			return x.Gauge
		}
	}
	return nil
}

func (x *Metric) GetSum() *Sum {
	if x != nil {
		if x, ok := x.xxx_hidden_Data.(*metric_Sum); ok {
			return x.Sum
		}
	}
	return nil
}

func (x *Metric) GetHistogram() *Histogram {
	if x != nil {
		if x, ok := x.xxx_hidden_Data.(*metric_Histogram); ok {
			return x.Histogram
		}
	}
	return nil
}

func (x *Metric) GetExponentialHistogram() *ExponentialHistogram {
	if x != nil {
		if x, ok := x.xxx_hidden_Data.(*metric_ExponentialHistogram); ok {
			return x.ExponentialHistogram
		}
	}
	return nil
}

func (x *Metric) GetSummary() *Summary {
	if x != nil {
		if x, ok := x.xxx_hidden_Data.(*metric_Summary); ok {
			return x.Summary
		}
	}
	return nil
}

func (x *Metric) GetMetadata() []*v11.KeyValue {
	if x != nil {
		if x.xxx_hidden_Metadata != nil {
			return *x.xxx_hidden_Metadata
		}
	}
	return nil
}

func (x *Metric) SetName(v string) {
	x.xxx_hidden_Name = v
}

func (x *Metric) SetDescription(v string) {
	x.xxx_hidden_Description = v
}

func (x *Metric) SetUnit(v string) {
	x.xxx_hidden_Unit = v
}

func (x *Metric) SetGauge(v *Gauge) {
	if v == nil {
		x.xxx_hidden_Data = nil
		return
	}
	x.xxx_hidden_Data = &metric_Gauge{v}
}

func (x *Metric) SetSum(v *Sum) {
	if v == nil {
		x.xxx_hidden_Data = nil
		return
	}
	x.xxx_hidden_Data = &metric_Sum{v}
}

func (x *Metric) SetHistogram(v *Histogram) {
	if v == nil {
		x.xxx_hidden_Data = nil
		return
	}
	x.xxx_hidden_Data = &metric_Histogram{v}
}

func (x *Metric) SetExponentialHistogram(v *ExponentialHistogram) {
	if v == nil {
		x.xxx_hidden_Data = nil
		return
	}
	x.xxx_hidden_Data = &metric_ExponentialHistogram{v}
}

func (x *Metric) SetSummary(v *Summary) {
	if v == nil {
		x.xxx_hidden_Data = nil
		return
	}
	x.xxx_hidden_Data = &metric_Summary{v}
}

func (x *Metric) SetMetadata(v []*v11.KeyValue) {
	x.xxx_hidden_Metadata = &v
}

func (x *Metric) HasData() bool {
	if x == nil {
		return false
	}
	return x.xxx_hidden_Data != nil
}

func (x *Metric) HasGauge() bool {
	if x == nil {
		return false
	}
	_, ok := x.xxx_hidden_Data.(*metric_Gauge)
	return ok
}

func (x *Metric) HasSum() bool {
	if x == nil {
		return false
	}
	_, ok := x.xxx_hidden_Data.(*metric_Sum)
	return ok
}

func (x *Metric) HasHistogram() bool {
	if x == nil {
		return false
	}
	_, ok := x.xxx_hidden_Data.(*metric_Histogram)
	return ok
}

func (x *Metric) HasExponentialHistogram() bool {
	if x == nil {
		return false
	}
	_, ok := x.xxx_hidden_Data.(*metric_ExponentialHistogram)
	return ok
}

func (x *Metric) HasSummary() bool {
	if x == nil {
		return false
	}
	_, ok := x.xxx_hidden_Data.(*metric_Summary)
	return ok
}

func (x *Metric) ClearData() {
	x.xxx_hidden_Data = nil
}

func (x *Metric) ClearGauge() {
	if _, ok := x.xxx_hidden_Data.(*metric_Gauge); ok {
		x.xxx_hidden_Data = nil
	}
}

func (x *Metric) ClearSum() {
	if _, ok := x.xxx_hidden_Data.(*metric_Sum); ok {
		x.xxx_hidden_Data = nil
	}
}

func (x *Metric) ClearHistogram() {
	if _, ok := x.xxx_hidden_Data.(*metric_Histogram); ok {
		x.xxx_hidden_Data = nil
	}
}

func (x *Metric) ClearExponentialHistogram() {
	if _, ok := x.xxx_hidden_Data.(*metric_ExponentialHistogram); ok {
		x.xxx_hidden_Data = nil
	}
}

func (x *Metric) ClearSummary() {
	if _, ok := x.xxx_hidden_Data.(*metric_Summary); ok {
		x.xxx_hidden_Data = nil
	}
}

const Metric_Data_not_set_case case_Metric_Data = 0
const Metric_Gauge_case case_Metric_Data = 5
const Metric_Sum_case case_Metric_Data = 7
const Metric_Histogram_case case_Metric_Data = 9
const Metric_ExponentialHistogram_case case_Metric_Data = 10
const Metric_Summary_case case_Metric_Data = 11

func (x *Metric) WhichData() case_Metric_Data {
	if x == nil {
		return Metric_Data_not_set_case
	}
	switch x.xxx_hidden_Data.(type) {
	case *metric_Gauge:
		return Metric_Gauge_case
	case *metric_Sum:
		return Metric_Sum_case
	case *metric_Histogram:
		return Metric_Histogram_case
	case *metric_ExponentialHistogram:
		return Metric_ExponentialHistogram_case
	case *metric_Summary:
		return Metric_Summary_case
	default:
		return Metric_Data_not_set_case
	}
}

type Metric_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The name of the metric.
	Name string
	// A description of the metric, which can be used in documentation.
	Description string
	// The unit in which the metric value is reported. Follows the format
	// described by https://unitsofmeasure.org/ucum.html.
	Unit string
	// Data determines the aggregation type (if any) of the metric, what is the
	// reported value type for the data points, as well as the relatationship to
	// the time interval over which they are reported.

	// Fields of oneof xxx_hidden_Data:
	Gauge                *Gauge
	Sum                  *Sum
	Histogram            *Histogram
	ExponentialHistogram *ExponentialHistogram
	Summary              *Summary
	// -- end of xxx_hidden_Data
	// Additional metadata attributes that describe the metric. [Optional].
	// Attributes are non-identifying.
	// Consumers SHOULD NOT need to be aware of these attributes.
	// These attributes MAY be used to encode information allowing
	// for lossless roundtrip translation to / from another data model.
	// Attribute keys MUST be unique (it is not allowed to have more than one
	// attribute with the same key).
	// The behavior of software that receives duplicated keys can be unpredictable.
	Metadata []*v11.KeyValue
}

func (b0 Metric_builder) Build() *Metric {
	m0 := &Metric{}
	b, x := &b0, m0
	_, _ = b, x
	x.xxx_hidden_Name = b.Name
	x.xxx_hidden_Description = b.Description
	x.xxx_hidden_Unit = b.Unit
	if b.Gauge != nil {
		x.xxx_hidden_Data = &metric_Gauge{b.Gauge}
	}
	if b.Sum != nil {
		x.xxx_hidden_Data = &metric_Sum{b.Sum}
	}
	if b.Histogram != nil {
		x.xxx_hidden_Data = &metric_Histogram{b.Histogram}
	}
	if b.ExponentialHistogram != nil {
		x.xxx_hidden_Data = &metric_ExponentialHistogram{b.ExponentialHistogram}
	}
	if b.Summary != nil {
		x.xxx_hidden_Data = &metric_Summary{b.Summary}
	}
	x.xxx_hidden_Metadata = &b.Metadata
	return m0
}

type case_Metric_Data protoreflect.FieldNumber

func (x case_Metric_Data) String() string {
	md := file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[3].Descriptor()
	if x == 0 {
		return "not set"
	}
	return protoimpl.X.MessageFieldStringOf(md, protoreflect.FieldNumber(x))
}

type isMetric_Data interface {
	isMetric_Data()
}

type metric_Gauge struct {
	Gauge *Gauge `protobuf:"bytes,5,opt,name=gauge,proto3,oneof"`
}

type metric_Sum struct {
	Sum *Sum `protobuf:"bytes,7,opt,name=sum,proto3,oneof"`
}

type metric_Histogram struct {
	Histogram *Histogram `protobuf:"bytes,9,opt,name=histogram,proto3,oneof"`
}

type metric_ExponentialHistogram struct {
	ExponentialHistogram *ExponentialHistogram `protobuf:"bytes,10,opt,name=exponential_histogram,json=exponentialHistogram,proto3,oneof"`
}

type metric_Summary struct {
	Summary *Summary `protobuf:"bytes,11,opt,name=summary,proto3,oneof"`
}

func (*metric_Gauge) isMetric_Data() {}

func (*metric_Sum) isMetric_Data() {}

func (*metric_Histogram) isMetric_Data() {}

func (*metric_ExponentialHistogram) isMetric_Data() {}

func (*metric_Summary) isMetric_Data() {}

// Gauge represents the type of a scalar metric that always exports the
// "current value" for every data point. It should be used for an "unknown"
// aggregation.
//
// A Gauge does not support different aggregation temporalities. Given the
// aggregation is unknown, points cannot be combined using the same
// aggregation, regardless of aggregation temporalities. Therefore,
// AggregationTemporality is not included. Consequently, this also means
// "StartTimeUnixNano" is ignored for all data points.
type Gauge struct {
	state                 protoimpl.MessageState `protogen:"opaque.v1"`
	xxx_hidden_DataPoints *[]*NumberDataPoint    `protobuf:"bytes,1,rep,name=data_points,json=dataPoints,proto3"`
	unknownFields         protoimpl.UnknownFields
	sizeCache             protoimpl.SizeCache
}

func (x *Gauge) Reset() {
	*x = Gauge{}
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Gauge) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Gauge) ProtoMessage() {}

func (x *Gauge) ProtoReflect() protoreflect.Message {
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *Gauge) GetDataPoints() []*NumberDataPoint {
	if x != nil {
		if x.xxx_hidden_DataPoints != nil {
			return *x.xxx_hidden_DataPoints
		}
	}
	return nil
}

func (x *Gauge) SetDataPoints(v []*NumberDataPoint) {
	x.xxx_hidden_DataPoints = &v
}

type Gauge_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The time series data points.
	// Note: Multiple time series may be included (same timestamp, different attributes).
	DataPoints []*NumberDataPoint
}

func (b0 Gauge_builder) Build() *Gauge {
	m0 := &Gauge{}
	b, x := &b0, m0
	_, _ = b, x
	x.xxx_hidden_DataPoints = &b.DataPoints
	return m0
}

// Sum represents the type of a scalar metric that is calculated as a sum of all
// reported measurements over a time interval.
type Sum struct {
	state                             protoimpl.MessageState `protogen:"opaque.v1"`
	xxx_hidden_DataPoints             *[]*NumberDataPoint    `protobuf:"bytes,1,rep,name=data_points,json=dataPoints,proto3"`
	xxx_hidden_AggregationTemporality AggregationTemporality `protobuf:"varint,2,opt,name=aggregation_temporality,json=aggregationTemporality,proto3,enum=opentelemetry.proto.metrics.v1.AggregationTemporality"`
	xxx_hidden_IsMonotonic            bool                   `protobuf:"varint,3,opt,name=is_monotonic,json=isMonotonic,proto3"`
	unknownFields                     protoimpl.UnknownFields
	sizeCache                         protoimpl.SizeCache
}

func (x *Sum) Reset() {
	*x = Sum{}
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Sum) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Sum) ProtoMessage() {}

func (x *Sum) ProtoReflect() protoreflect.Message {
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *Sum) GetDataPoints() []*NumberDataPoint {
	if x != nil {
		if x.xxx_hidden_DataPoints != nil {
			return *x.xxx_hidden_DataPoints
		}
	}
	return nil
}

func (x *Sum) GetAggregationTemporality() AggregationTemporality {
	if x != nil {
		return x.xxx_hidden_AggregationTemporality
	}
	return AggregationTemporality_AGGREGATION_TEMPORALITY_UNSPECIFIED
}

func (x *Sum) GetIsMonotonic() bool {
	if x != nil {
		return x.xxx_hidden_IsMonotonic
	}
	return false
}

func (x *Sum) SetDataPoints(v []*NumberDataPoint) {
	x.xxx_hidden_DataPoints = &v
}

func (x *Sum) SetAggregationTemporality(v AggregationTemporality) {
	x.xxx_hidden_AggregationTemporality = v
}

func (x *Sum) SetIsMonotonic(v bool) {
	x.xxx_hidden_IsMonotonic = v
}

type Sum_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The time series data points.
	// Note: Multiple time series may be included (same timestamp, different attributes).
	DataPoints []*NumberDataPoint
	// aggregation_temporality describes if the aggregator reports delta changes
	// since last report time, or cumulative changes since a fixed start time.
	AggregationTemporality AggregationTemporality
	// Represents whether the sum is monotonic.
	IsMonotonic bool
}

func (b0 Sum_builder) Build() *Sum {
	m0 := &Sum{}
	b, x := &b0, m0
	_, _ = b, x
	x.xxx_hidden_DataPoints = &b.DataPoints
	x.xxx_hidden_AggregationTemporality = b.AggregationTemporality
	x.xxx_hidden_IsMonotonic = b.IsMonotonic
	return m0
}

// Histogram represents the type of a metric that is calculated by aggregating
// as a Histogram of all reported measurements over a time interval.
type Histogram struct {
	state                             protoimpl.MessageState `protogen:"opaque.v1"`
	xxx_hidden_DataPoints             *[]*HistogramDataPoint `protobuf:"bytes,1,rep,name=data_points,json=dataPoints,proto3"`
	xxx_hidden_AggregationTemporality AggregationTemporality `protobuf:"varint,2,opt,name=aggregation_temporality,json=aggregationTemporality,proto3,enum=opentelemetry.proto.metrics.v1.AggregationTemporality"`
	unknownFields                     protoimpl.UnknownFields
	sizeCache                         protoimpl.SizeCache
}

func (x *Histogram) Reset() {
	*x = Histogram{}
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Histogram) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Histogram) ProtoMessage() {}

func (x *Histogram) ProtoReflect() protoreflect.Message {
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *Histogram) GetDataPoints() []*HistogramDataPoint {
	if x != nil {
		if x.xxx_hidden_DataPoints != nil {
			return *x.xxx_hidden_DataPoints
		}
	}
	return nil
}

func (x *Histogram) GetAggregationTemporality() AggregationTemporality {
	if x != nil {
		return x.xxx_hidden_AggregationTemporality
	}
	return AggregationTemporality_AGGREGATION_TEMPORALITY_UNSPECIFIED
}

func (x *Histogram) SetDataPoints(v []*HistogramDataPoint) {
	x.xxx_hidden_DataPoints = &v
}

func (x *Histogram) SetAggregationTemporality(v AggregationTemporality) {
	x.xxx_hidden_AggregationTemporality = v
}

type Histogram_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The time series data points.
	// Note: Multiple time series may be included (same timestamp, different attributes).
	DataPoints []*HistogramDataPoint
	// aggregation_temporality describes if the aggregator reports delta changes
	// since last report time, or cumulative changes since a fixed start time.
	AggregationTemporality AggregationTemporality
}

func (b0 Histogram_builder) Build() *Histogram {
	m0 := &Histogram{}
	b, x := &b0, m0
	_, _ = b, x
	x.xxx_hidden_DataPoints = &b.DataPoints
	x.xxx_hidden_AggregationTemporality = b.AggregationTemporality
	return m0
}

// ExponentialHistogram represents the type of a metric that is calculated by aggregating
// as a ExponentialHistogram of all reported double measurements over a time interval.
type ExponentialHistogram struct {
	state                             protoimpl.MessageState            `protogen:"opaque.v1"`
	xxx_hidden_DataPoints             *[]*ExponentialHistogramDataPoint `protobuf:"bytes,1,rep,name=data_points,json=dataPoints,proto3"`
	xxx_hidden_AggregationTemporality AggregationTemporality            `protobuf:"varint,2,opt,name=aggregation_temporality,json=aggregationTemporality,proto3,enum=opentelemetry.proto.metrics.v1.AggregationTemporality"`
	unknownFields                     protoimpl.UnknownFields
	sizeCache                         protoimpl.SizeCache
}

func (x *ExponentialHistogram) Reset() {
	*x = ExponentialHistogram{}
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ExponentialHistogram) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ExponentialHistogram) ProtoMessage() {}

func (x *ExponentialHistogram) ProtoReflect() protoreflect.Message {
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *ExponentialHistogram) GetDataPoints() []*ExponentialHistogramDataPoint {
	if x != nil {
		if x.xxx_hidden_DataPoints != nil {
			return *x.xxx_hidden_DataPoints
		}
	}
	return nil
}

func (x *ExponentialHistogram) GetAggregationTemporality() AggregationTemporality {
	if x != nil {
		return x.xxx_hidden_AggregationTemporality
	}
	return AggregationTemporality_AGGREGATION_TEMPORALITY_UNSPECIFIED
}

func (x *ExponentialHistogram) SetDataPoints(v []*ExponentialHistogramDataPoint) {
	x.xxx_hidden_DataPoints = &v
}

func (x *ExponentialHistogram) SetAggregationTemporality(v AggregationTemporality) {
	x.xxx_hidden_AggregationTemporality = v
}

type ExponentialHistogram_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The time series data points.
	// Note: Multiple time series may be included (same timestamp, different attributes).
	DataPoints []*ExponentialHistogramDataPoint
	// aggregation_temporality describes if the aggregator reports delta changes
	// since last report time, or cumulative changes since a fixed start time.
	AggregationTemporality AggregationTemporality
}

func (b0 ExponentialHistogram_builder) Build() *ExponentialHistogram {
	m0 := &ExponentialHistogram{}
	b, x := &b0, m0
	_, _ = b, x
	x.xxx_hidden_DataPoints = &b.DataPoints
	x.xxx_hidden_AggregationTemporality = b.AggregationTemporality
	return m0
}

// Summary metric data are used to convey quantile summaries,
// a Prometheus (see: https://prometheus.io/docs/concepts/metric_types/#summary)
// and OpenMetrics (see: https://github.com/prometheus/OpenMetrics/blob/4dbf6075567ab43296eed941037c12951faafb92/protos/prometheus.proto#L45)
// data type. These data points cannot always be merged in a meaningful way.
// While they can be useful in some applications, histogram data points are
// recommended for new applications.
// Summary metrics do not have an aggregation temporality field. This is
// because the count and sum fields of a SummaryDataPoint are assumed to be
// cumulative values.
type Summary struct {
	state                 protoimpl.MessageState `protogen:"opaque.v1"`
	xxx_hidden_DataPoints *[]*SummaryDataPoint   `protobuf:"bytes,1,rep,name=data_points,json=dataPoints,proto3"`
	unknownFields         protoimpl.UnknownFields
	sizeCache             protoimpl.SizeCache
}

func (x *Summary) Reset() {
	*x = Summary{}
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Summary) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Summary) ProtoMessage() {}

func (x *Summary) ProtoReflect() protoreflect.Message {
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *Summary) GetDataPoints() []*SummaryDataPoint {
	if x != nil {
		if x.xxx_hidden_DataPoints != nil {
			return *x.xxx_hidden_DataPoints
		}
	}
	return nil
}

func (x *Summary) SetDataPoints(v []*SummaryDataPoint) {
	x.xxx_hidden_DataPoints = &v
}

type Summary_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The time series data points.
	// Note: Multiple time series may be included (same timestamp, different attributes).
	DataPoints []*SummaryDataPoint
}

func (b0 Summary_builder) Build() *Summary {
	m0 := &Summary{}
	b, x := &b0, m0
	_, _ = b, x
	x.xxx_hidden_DataPoints = &b.DataPoints
	return m0
}

// NumberDataPoint is a single data point in a timeseries that describes the
// time-varying scalar value of a metric.
type NumberDataPoint struct {
	state                        protoimpl.MessageState  `protogen:"opaque.v1"`
	xxx_hidden_Attributes        *[]*v11.KeyValue        `protobuf:"bytes,7,rep,name=attributes,proto3"`
	xxx_hidden_StartTimeUnixNano uint64                  `protobuf:"fixed64,2,opt,name=start_time_unix_nano,json=startTimeUnixNano,proto3"`
	xxx_hidden_TimeUnixNano      uint64                  `protobuf:"fixed64,3,opt,name=time_unix_nano,json=timeUnixNano,proto3"`
	xxx_hidden_Value             isNumberDataPoint_Value `protobuf_oneof:"value"`
	xxx_hidden_Exemplars         *[]*Exemplar            `protobuf:"bytes,5,rep,name=exemplars,proto3"`
	xxx_hidden_Flags             uint32                  `protobuf:"varint,8,opt,name=flags,proto3"`
	unknownFields                protoimpl.UnknownFields
	sizeCache                    protoimpl.SizeCache
}

func (x *NumberDataPoint) Reset() {
	*x = NumberDataPoint{}
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *NumberDataPoint) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*NumberDataPoint) ProtoMessage() {}

func (x *NumberDataPoint) ProtoReflect() protoreflect.Message {
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *NumberDataPoint) GetAttributes() []*v11.KeyValue {
	if x != nil {
		if x.xxx_hidden_Attributes != nil {
			return *x.xxx_hidden_Attributes
		}
	}
	return nil
}

func (x *NumberDataPoint) GetStartTimeUnixNano() uint64 {
	if x != nil {
		return x.xxx_hidden_StartTimeUnixNano
	}
	return 0
}

func (x *NumberDataPoint) GetTimeUnixNano() uint64 {
	if x != nil {
		return x.xxx_hidden_TimeUnixNano
	}
	return 0
}

func (x *NumberDataPoint) GetAsDouble() float64 {
	if x != nil {
		if x, ok := x.xxx_hidden_Value.(*numberDataPoint_AsDouble); ok {
			return x.AsDouble
		}
	}
	return 0
}

func (x *NumberDataPoint) GetAsInt() int64 {
	if x != nil {
		if x, ok := x.xxx_hidden_Value.(*numberDataPoint_AsInt); ok {
			return x.AsInt
		}
	}
	return 0
}

func (x *NumberDataPoint) GetExemplars() []*Exemplar {
	if x != nil {
		if x.xxx_hidden_Exemplars != nil {
			return *x.xxx_hidden_Exemplars
		}
	}
	return nil
}

func (x *NumberDataPoint) GetFlags() uint32 {
	if x != nil {
		return x.xxx_hidden_Flags
	}
	return 0
}

func (x *NumberDataPoint) SetAttributes(v []*v11.KeyValue) {
	x.xxx_hidden_Attributes = &v
}

func (x *NumberDataPoint) SetStartTimeUnixNano(v uint64) {
	x.xxx_hidden_StartTimeUnixNano = v
}

func (x *NumberDataPoint) SetTimeUnixNano(v uint64) {
	x.xxx_hidden_TimeUnixNano = v
}

func (x *NumberDataPoint) SetAsDouble(v float64) {
	x.xxx_hidden_Value = &numberDataPoint_AsDouble{v}
}

func (x *NumberDataPoint) SetAsInt(v int64) {
	x.xxx_hidden_Value = &numberDataPoint_AsInt{v}
}

func (x *NumberDataPoint) SetExemplars(v []*Exemplar) {
	x.xxx_hidden_Exemplars = &v
}

func (x *NumberDataPoint) SetFlags(v uint32) {
	x.xxx_hidden_Flags = v
}

func (x *NumberDataPoint) HasValue() bool {
	if x == nil {
		return false
	}
	return x.xxx_hidden_Value != nil
}

func (x *NumberDataPoint) HasAsDouble() bool {
	if x == nil {
		return false
	}
	_, ok := x.xxx_hidden_Value.(*numberDataPoint_AsDouble)
	return ok
}

func (x *NumberDataPoint) HasAsInt() bool {
	if x == nil {
		return false
	}
	_, ok := x.xxx_hidden_Value.(*numberDataPoint_AsInt)
	return ok
}

func (x *NumberDataPoint) ClearValue() {
	x.xxx_hidden_Value = nil
}

func (x *NumberDataPoint) ClearAsDouble() {
	if _, ok := x.xxx_hidden_Value.(*numberDataPoint_AsDouble); ok {
		x.xxx_hidden_Value = nil
	}
}

func (x *NumberDataPoint) ClearAsInt() {
	if _, ok := x.xxx_hidden_Value.(*numberDataPoint_AsInt); ok {
		x.xxx_hidden_Value = nil
	}
}

const NumberDataPoint_Value_not_set_case case_NumberDataPoint_Value = 0
const NumberDataPoint_AsDouble_case case_NumberDataPoint_Value = 4
const NumberDataPoint_AsInt_case case_NumberDataPoint_Value = 6

func (x *NumberDataPoint) WhichValue() case_NumberDataPoint_Value {
	if x == nil {
		return NumberDataPoint_Value_not_set_case
	}
	switch x.xxx_hidden_Value.(type) {
	case *numberDataPoint_AsDouble:
		return NumberDataPoint_AsDouble_case
	case *numberDataPoint_AsInt:
		return NumberDataPoint_AsInt_case
	default:
		return NumberDataPoint_Value_not_set_case
	}
}

type NumberDataPoint_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The set of key/value pairs that uniquely identify the timeseries from
	// where this point belongs. The list may be empty (may contain 0 elements).
	// Attribute keys MUST be unique (it is not allowed to have more than one
	// attribute with the same key).
	// The behavior of software that receives duplicated keys can be unpredictable.
	Attributes []*v11.KeyValue
	// StartTimeUnixNano is optional but strongly encouraged, see the
	// the detailed comments above Metric.
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	StartTimeUnixNano uint64
	// TimeUnixNano is required, see the detailed comments above Metric.
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	TimeUnixNano uint64
	// The value itself.  A point is considered invalid when one of the recognized
	// value fields is not present inside this oneof.

	// Fields of oneof xxx_hidden_Value:
	AsDouble *float64
	AsInt    *int64
	// -- end of xxx_hidden_Value
	// (Optional) List of exemplars collected from
	// measurements that were used to form the data point
	Exemplars []*Exemplar
	// Flags that apply to this specific data point.  See DataPointFlags
	// for the available flags and their meaning.
	Flags uint32
}

func (b0 NumberDataPoint_builder) Build() *NumberDataPoint {
	m0 := &NumberDataPoint{}
	b, x := &b0, m0
	_, _ = b, x
	x.xxx_hidden_Attributes = &b.Attributes
	x.xxx_hidden_StartTimeUnixNano = b.StartTimeUnixNano
	x.xxx_hidden_TimeUnixNano = b.TimeUnixNano
	if b.AsDouble != nil {
		x.xxx_hidden_Value = &numberDataPoint_AsDouble{*b.AsDouble}
	}
	if b.AsInt != nil {
		x.xxx_hidden_Value = &numberDataPoint_AsInt{*b.AsInt}
	}
	x.xxx_hidden_Exemplars = &b.Exemplars
	x.xxx_hidden_Flags = b.Flags
	return m0
}

type case_NumberDataPoint_Value protoreflect.FieldNumber

func (x case_NumberDataPoint_Value) String() string {
	md := file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[9].Descriptor()
	if x == 0 {
		return "not set"
	}
	return protoimpl.X.MessageFieldStringOf(md, protoreflect.FieldNumber(x))
}

type isNumberDataPoint_Value interface {
	isNumberDataPoint_Value()
}

type numberDataPoint_AsDouble struct {
	AsDouble float64 `protobuf:"fixed64,4,opt,name=as_double,json=asDouble,proto3,oneof"`
}

type numberDataPoint_AsInt struct {
	AsInt int64 `protobuf:"fixed64,6,opt,name=as_int,json=asInt,proto3,oneof"`
}

func (*numberDataPoint_AsDouble) isNumberDataPoint_Value() {}

func (*numberDataPoint_AsInt) isNumberDataPoint_Value() {}

// HistogramDataPoint is a single data point in a timeseries that describes the
// time-varying values of a Histogram. A Histogram contains summary statistics
// for a population of values, it may optionally contain the distribution of
// those values across a set of buckets.
//
// If the histogram contains the distribution of values, then both
// "explicit_bounds" and "bucket counts" fields must be defined.
// If the histogram does not contain the distribution of values, then both
// "explicit_bounds" and "bucket_counts" must be omitted and only "count" and
// "sum" are known.
type HistogramDataPoint struct {
	state                        protoimpl.MessageState `protogen:"opaque.v1"`
	xxx_hidden_Attributes        *[]*v11.KeyValue       `protobuf:"bytes,9,rep,name=attributes,proto3"`
	xxx_hidden_StartTimeUnixNano uint64                 `protobuf:"fixed64,2,opt,name=start_time_unix_nano,json=startTimeUnixNano,proto3"`
	xxx_hidden_TimeUnixNano      uint64                 `protobuf:"fixed64,3,opt,name=time_unix_nano,json=timeUnixNano,proto3"`
	xxx_hidden_Count             uint64                 `protobuf:"fixed64,4,opt,name=count,proto3"`
	xxx_hidden_Sum               float64                `protobuf:"fixed64,5,opt,name=sum,proto3,oneof"`
	xxx_hidden_BucketCounts      []uint64               `protobuf:"fixed64,6,rep,packed,name=bucket_counts,json=bucketCounts,proto3"`
	xxx_hidden_ExplicitBounds    []float64              `protobuf:"fixed64,7,rep,packed,name=explicit_bounds,json=explicitBounds,proto3"`
	xxx_hidden_Exemplars         *[]*Exemplar           `protobuf:"bytes,8,rep,name=exemplars,proto3"`
	xxx_hidden_Flags             uint32                 `protobuf:"varint,10,opt,name=flags,proto3"`
	xxx_hidden_Min               float64                `protobuf:"fixed64,11,opt,name=min,proto3,oneof"`
	xxx_hidden_Max               float64                `protobuf:"fixed64,12,opt,name=max,proto3,oneof"`
	XXX_raceDetectHookData       protoimpl.RaceDetectHookData
	XXX_presence                 [1]uint32
	unknownFields                protoimpl.UnknownFields
	sizeCache                    protoimpl.SizeCache
}

func (x *HistogramDataPoint) Reset() {
	*x = HistogramDataPoint{}
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *HistogramDataPoint) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HistogramDataPoint) ProtoMessage() {}

func (x *HistogramDataPoint) ProtoReflect() protoreflect.Message {
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *HistogramDataPoint) GetAttributes() []*v11.KeyValue {
	if x != nil {
		if x.xxx_hidden_Attributes != nil {
			return *x.xxx_hidden_Attributes
		}
	}
	return nil
}

func (x *HistogramDataPoint) GetStartTimeUnixNano() uint64 {
	if x != nil {
		return x.xxx_hidden_StartTimeUnixNano
	}
	return 0
}

func (x *HistogramDataPoint) GetTimeUnixNano() uint64 {
	if x != nil {
		return x.xxx_hidden_TimeUnixNano
	}
	return 0
}

func (x *HistogramDataPoint) GetCount() uint64 {
	if x != nil {
		return x.xxx_hidden_Count
	}
	return 0
}

func (x *HistogramDataPoint) GetSum() float64 {
	if x != nil {
		return x.xxx_hidden_Sum
	}
	return 0
}

func (x *HistogramDataPoint) GetBucketCounts() []uint64 {
	if x != nil {
		return x.xxx_hidden_BucketCounts
	}
	return nil
}

func (x *HistogramDataPoint) GetExplicitBounds() []float64 {
	if x != nil {
		return x.xxx_hidden_ExplicitBounds
	}
	return nil
}

func (x *HistogramDataPoint) GetExemplars() []*Exemplar {
	if x != nil {
		if x.xxx_hidden_Exemplars != nil {
			return *x.xxx_hidden_Exemplars
		}
	}
	return nil
}

func (x *HistogramDataPoint) GetFlags() uint32 {
	if x != nil {
		return x.xxx_hidden_Flags
	}
	return 0
}

func (x *HistogramDataPoint) GetMin() float64 {
	if x != nil {
		return x.xxx_hidden_Min
	}
	return 0
}

func (x *HistogramDataPoint) GetMax() float64 {
	if x != nil {
		return x.xxx_hidden_Max
	}
	return 0
}

func (x *HistogramDataPoint) SetAttributes(v []*v11.KeyValue) {
	x.xxx_hidden_Attributes = &v
}

func (x *HistogramDataPoint) SetStartTimeUnixNano(v uint64) {
	x.xxx_hidden_StartTimeUnixNano = v
}

func (x *HistogramDataPoint) SetTimeUnixNano(v uint64) {
	x.xxx_hidden_TimeUnixNano = v
}

func (x *HistogramDataPoint) SetCount(v uint64) {
	x.xxx_hidden_Count = v
}

func (x *HistogramDataPoint) SetSum(v float64) {
	x.xxx_hidden_Sum = v
	protoimpl.X.SetPresent(&(x.XXX_presence[0]), 4, 11)
}

func (x *HistogramDataPoint) SetBucketCounts(v []uint64) {
	x.xxx_hidden_BucketCounts = v
}

func (x *HistogramDataPoint) SetExplicitBounds(v []float64) {
	x.xxx_hidden_ExplicitBounds = v
}

func (x *HistogramDataPoint) SetExemplars(v []*Exemplar) {
	x.xxx_hidden_Exemplars = &v
}

func (x *HistogramDataPoint) SetFlags(v uint32) {
	x.xxx_hidden_Flags = v
}

func (x *HistogramDataPoint) SetMin(v float64) {
	x.xxx_hidden_Min = v
	protoimpl.X.SetPresent(&(x.XXX_presence[0]), 9, 11)
}

func (x *HistogramDataPoint) SetMax(v float64) {
	x.xxx_hidden_Max = v
	protoimpl.X.SetPresent(&(x.XXX_presence[0]), 10, 11)
}

func (x *HistogramDataPoint) HasSum() bool {
	if x == nil {
		return false
	}
	return protoimpl.X.Present(&(x.XXX_presence[0]), 4)
}

func (x *HistogramDataPoint) HasMin() bool {
	if x == nil {
		return false
	}
	return protoimpl.X.Present(&(x.XXX_presence[0]), 9)
}

func (x *HistogramDataPoint) HasMax() bool {
	if x == nil {
		return false
	}
	return protoimpl.X.Present(&(x.XXX_presence[0]), 10)
}

func (x *HistogramDataPoint) ClearSum() {
	protoimpl.X.ClearPresent(&(x.XXX_presence[0]), 4)
	x.xxx_hidden_Sum = 0
}

func (x *HistogramDataPoint) ClearMin() {
	protoimpl.X.ClearPresent(&(x.XXX_presence[0]), 9)
	x.xxx_hidden_Min = 0
}

func (x *HistogramDataPoint) ClearMax() {
	protoimpl.X.ClearPresent(&(x.XXX_presence[0]), 10)
	x.xxx_hidden_Max = 0
}

type HistogramDataPoint_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The set of key/value pairs that uniquely identify the timeseries from
	// where this point belongs. The list may be empty (may contain 0 elements).
	// Attribute keys MUST be unique (it is not allowed to have more than one
	// attribute with the same key).
	// The behavior of software that receives duplicated keys can be unpredictable.
	Attributes []*v11.KeyValue
	// StartTimeUnixNano is optional but strongly encouraged, see the
	// the detailed comments above Metric.
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	StartTimeUnixNano uint64
	// TimeUnixNano is required, see the detailed comments above Metric.
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	TimeUnixNano uint64
	// count is the number of values in the population. Must be non-negative. This
	// value must be equal to the sum of the "count" fields in buckets if a
	// histogram is provided.
	Count uint64
	// sum of the values in the population. If count is zero then this field
	// must be zero.
	//
	// Note: Sum should only be filled out when measuring non-negative discrete
	// events, and is assumed to be monotonic over the values of these events.
	// Negative events *can* be recorded, but sum should not be filled out when
	// doing so.  This is specifically to enforce compatibility w/ OpenMetrics,
	// see: https://github.com/prometheus/OpenMetrics/blob/v1.0.0/specification/OpenMetrics.md#histogram
	Sum *float64
	// bucket_counts is an optional field contains the count values of histogram
	// for each bucket.
	//
	// The sum of the bucket_counts must equal the value in the count field.
	//
	// The number of elements in bucket_counts array must be by one greater than
	// the number of elements in explicit_bounds array. The exception to this rule
	// is when the length of bucket_counts is 0, then the length of explicit_bounds
	// must also be 0.
	BucketCounts []uint64
	// explicit_bounds specifies buckets with explicitly defined bounds for values.
	//
	// The boundaries for bucket at index i are:
	//
	// (-infinity, explicit_bounds[i]] for i == 0
	// (explicit_bounds[i-1], explicit_bounds[i]] for 0 < i < size(explicit_bounds)
	// (explicit_bounds[i-1], +infinity) for i == size(explicit_bounds)
	//
	// The values in the explicit_bounds array must be strictly increasing.
	//
	// Histogram buckets are inclusive of their upper boundary, except the last
	// bucket where the boundary is at infinity. This format is intentionally
	// compatible with the OpenMetrics histogram definition.
	//
	// If bucket_counts length is 0 then explicit_bounds length must also be 0,
	// otherwise the data point is invalid.
	ExplicitBounds []float64
	// (Optional) List of exemplars collected from
	// measurements that were used to form the data point
	Exemplars []*Exemplar
	// Flags that apply to this specific data point.  See DataPointFlags
	// for the available flags and their meaning.
	Flags uint32
	// min is the minimum value over (start_time, end_time].
	Min *float64
	// max is the maximum value over (start_time, end_time].
	Max *float64
}

func (b0 HistogramDataPoint_builder) Build() *HistogramDataPoint {
	m0 := &HistogramDataPoint{}
	b, x := &b0, m0
	_, _ = b, x
	x.xxx_hidden_Attributes = &b.Attributes
	x.xxx_hidden_StartTimeUnixNano = b.StartTimeUnixNano
	x.xxx_hidden_TimeUnixNano = b.TimeUnixNano
	x.xxx_hidden_Count = b.Count
	if b.Sum != nil {
		protoimpl.X.SetPresentNonAtomic(&(x.XXX_presence[0]), 4, 11)
		x.xxx_hidden_Sum = *b.Sum
	}
	x.xxx_hidden_BucketCounts = b.BucketCounts
	x.xxx_hidden_ExplicitBounds = b.ExplicitBounds
	x.xxx_hidden_Exemplars = &b.Exemplars
	x.xxx_hidden_Flags = b.Flags
	if b.Min != nil {
		protoimpl.X.SetPresentNonAtomic(&(x.XXX_presence[0]), 9, 11)
		x.xxx_hidden_Min = *b.Min
	}
	if b.Max != nil {
		protoimpl.X.SetPresentNonAtomic(&(x.XXX_presence[0]), 10, 11)
		x.xxx_hidden_Max = *b.Max
	}
	return m0
}

// ExponentialHistogramDataPoint is a single data point in a timeseries that describes the
// time-varying values of a ExponentialHistogram of double values. A ExponentialHistogram contains
// summary statistics for a population of values, it may optionally contain the
// distribution of those values across a set of buckets.
type ExponentialHistogramDataPoint struct {
	state                        protoimpl.MessageState                 `protogen:"opaque.v1"`
	xxx_hidden_Attributes        *[]*v11.KeyValue                       `protobuf:"bytes,1,rep,name=attributes,proto3"`
	xxx_hidden_StartTimeUnixNano uint64                                 `protobuf:"fixed64,2,opt,name=start_time_unix_nano,json=startTimeUnixNano,proto3"`
	xxx_hidden_TimeUnixNano      uint64                                 `protobuf:"fixed64,3,opt,name=time_unix_nano,json=timeUnixNano,proto3"`
	xxx_hidden_Count             uint64                                 `protobuf:"fixed64,4,opt,name=count,proto3"`
	xxx_hidden_Sum               float64                                `protobuf:"fixed64,5,opt,name=sum,proto3,oneof"`
	xxx_hidden_Scale             int32                                  `protobuf:"zigzag32,6,opt,name=scale,proto3"`
	xxx_hidden_ZeroCount         uint64                                 `protobuf:"fixed64,7,opt,name=zero_count,json=zeroCount,proto3"`
	xxx_hidden_Positive          *ExponentialHistogramDataPoint_Buckets `protobuf:"bytes,8,opt,name=positive,proto3"`
	xxx_hidden_Negative          *ExponentialHistogramDataPoint_Buckets `protobuf:"bytes,9,opt,name=negative,proto3"`
	xxx_hidden_Flags             uint32                                 `protobuf:"varint,10,opt,name=flags,proto3"`
	xxx_hidden_Exemplars         *[]*Exemplar                           `protobuf:"bytes,11,rep,name=exemplars,proto3"`
	xxx_hidden_Min               float64                                `protobuf:"fixed64,12,opt,name=min,proto3,oneof"`
	xxx_hidden_Max               float64                                `protobuf:"fixed64,13,opt,name=max,proto3,oneof"`
	xxx_hidden_ZeroThreshold     float64                                `protobuf:"fixed64,14,opt,name=zero_threshold,json=zeroThreshold,proto3"`
	XXX_raceDetectHookData       protoimpl.RaceDetectHookData
	XXX_presence                 [1]uint32
	unknownFields                protoimpl.UnknownFields
	sizeCache                    protoimpl.SizeCache
}

func (x *ExponentialHistogramDataPoint) Reset() {
	*x = ExponentialHistogramDataPoint{}
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ExponentialHistogramDataPoint) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ExponentialHistogramDataPoint) ProtoMessage() {}

func (x *ExponentialHistogramDataPoint) ProtoReflect() protoreflect.Message {
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *ExponentialHistogramDataPoint) GetAttributes() []*v11.KeyValue {
	if x != nil {
		if x.xxx_hidden_Attributes != nil {
			return *x.xxx_hidden_Attributes
		}
	}
	return nil
}

func (x *ExponentialHistogramDataPoint) GetStartTimeUnixNano() uint64 {
	if x != nil {
		return x.xxx_hidden_StartTimeUnixNano
	}
	return 0
}

func (x *ExponentialHistogramDataPoint) GetTimeUnixNano() uint64 {
	if x != nil {
		return x.xxx_hidden_TimeUnixNano
	}
	return 0
}

func (x *ExponentialHistogramDataPoint) GetCount() uint64 {
	if x != nil {
		return x.xxx_hidden_Count
	}
	return 0
}

func (x *ExponentialHistogramDataPoint) GetSum() float64 {
	if x != nil {
		return x.xxx_hidden_Sum
	}
	return 0
}

func (x *ExponentialHistogramDataPoint) GetScale() int32 {
	if x != nil {
		return x.xxx_hidden_Scale
	}
	return 0
}

func (x *ExponentialHistogramDataPoint) GetZeroCount() uint64 {
	if x != nil {
		return x.xxx_hidden_ZeroCount
	}
	return 0
}

func (x *ExponentialHistogramDataPoint) GetPositive() *ExponentialHistogramDataPoint_Buckets {
	if x != nil {
		return x.xxx_hidden_Positive
	}
	return nil
}

func (x *ExponentialHistogramDataPoint) GetNegative() *ExponentialHistogramDataPoint_Buckets {
	if x != nil {
		return x.xxx_hidden_Negative
	}
	return nil
}

func (x *ExponentialHistogramDataPoint) GetFlags() uint32 {
	if x != nil {
		return x.xxx_hidden_Flags
	}
	return 0
}

func (x *ExponentialHistogramDataPoint) GetExemplars() []*Exemplar {
	if x != nil {
		if x.xxx_hidden_Exemplars != nil {
			return *x.xxx_hidden_Exemplars
		}
	}
	return nil
}

func (x *ExponentialHistogramDataPoint) GetMin() float64 {
	if x != nil {
		return x.xxx_hidden_Min
	}
	return 0
}

func (x *ExponentialHistogramDataPoint) GetMax() float64 {
	if x != nil {
		return x.xxx_hidden_Max
	}
	return 0
}

func (x *ExponentialHistogramDataPoint) GetZeroThreshold() float64 {
	if x != nil {
		return x.xxx_hidden_ZeroThreshold
	}
	return 0
}

func (x *ExponentialHistogramDataPoint) SetAttributes(v []*v11.KeyValue) {
	x.xxx_hidden_Attributes = &v
}

func (x *ExponentialHistogramDataPoint) SetStartTimeUnixNano(v uint64) {
	x.xxx_hidden_StartTimeUnixNano = v
}

func (x *ExponentialHistogramDataPoint) SetTimeUnixNano(v uint64) {
	x.xxx_hidden_TimeUnixNano = v
}

func (x *ExponentialHistogramDataPoint) SetCount(v uint64) {
	x.xxx_hidden_Count = v
}

func (x *ExponentialHistogramDataPoint) SetSum(v float64) {
	x.xxx_hidden_Sum = v
	protoimpl.X.SetPresent(&(x.XXX_presence[0]), 4, 14)
}

func (x *ExponentialHistogramDataPoint) SetScale(v int32) {
	x.xxx_hidden_Scale = v
}

func (x *ExponentialHistogramDataPoint) SetZeroCount(v uint64) {
	x.xxx_hidden_ZeroCount = v
}

func (x *ExponentialHistogramDataPoint) SetPositive(v *ExponentialHistogramDataPoint_Buckets) {
	x.xxx_hidden_Positive = v
}

func (x *ExponentialHistogramDataPoint) SetNegative(v *ExponentialHistogramDataPoint_Buckets) {
	x.xxx_hidden_Negative = v
}

func (x *ExponentialHistogramDataPoint) SetFlags(v uint32) {
	x.xxx_hidden_Flags = v
}

func (x *ExponentialHistogramDataPoint) SetExemplars(v []*Exemplar) {
	x.xxx_hidden_Exemplars = &v
}

func (x *ExponentialHistogramDataPoint) SetMin(v float64) {
	x.xxx_hidden_Min = v
	protoimpl.X.SetPresent(&(x.XXX_presence[0]), 11, 14)
}

func (x *ExponentialHistogramDataPoint) SetMax(v float64) {
	x.xxx_hidden_Max = v
	protoimpl.X.SetPresent(&(x.XXX_presence[0]), 12, 14)
}

func (x *ExponentialHistogramDataPoint) SetZeroThreshold(v float64) {
	x.xxx_hidden_ZeroThreshold = v
}

func (x *ExponentialHistogramDataPoint) HasSum() bool {
	if x == nil {
		return false
	}
	return protoimpl.X.Present(&(x.XXX_presence[0]), 4)
}

func (x *ExponentialHistogramDataPoint) HasPositive() bool {
	if x == nil {
		return false
	}
	return x.xxx_hidden_Positive != nil
}

func (x *ExponentialHistogramDataPoint) HasNegative() bool {
	if x == nil {
		return false
	}
	return x.xxx_hidden_Negative != nil
}

func (x *ExponentialHistogramDataPoint) HasMin() bool {
	if x == nil {
		return false
	}
	return protoimpl.X.Present(&(x.XXX_presence[0]), 11)
}

func (x *ExponentialHistogramDataPoint) HasMax() bool {
	if x == nil {
		return false
	}
	return protoimpl.X.Present(&(x.XXX_presence[0]), 12)
}

func (x *ExponentialHistogramDataPoint) ClearSum() {
	protoimpl.X.ClearPresent(&(x.XXX_presence[0]), 4)
	x.xxx_hidden_Sum = 0
}

func (x *ExponentialHistogramDataPoint) ClearPositive() {
	x.xxx_hidden_Positive = nil
}

func (x *ExponentialHistogramDataPoint) ClearNegative() {
	x.xxx_hidden_Negative = nil
}

func (x *ExponentialHistogramDataPoint) ClearMin() {
	protoimpl.X.ClearPresent(&(x.XXX_presence[0]), 11)
	x.xxx_hidden_Min = 0
}

func (x *ExponentialHistogramDataPoint) ClearMax() {
	protoimpl.X.ClearPresent(&(x.XXX_presence[0]), 12)
	x.xxx_hidden_Max = 0
}

type ExponentialHistogramDataPoint_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The set of key/value pairs that uniquely identify the timeseries from
	// where this point belongs. The list may be empty (may contain 0 elements).
	// Attribute keys MUST be unique (it is not allowed to have more than one
	// attribute with the same key).
	// The behavior of software that receives duplicated keys can be unpredictable.
	Attributes []*v11.KeyValue
	// StartTimeUnixNano is optional but strongly encouraged, see the
	// the detailed comments above Metric.
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	StartTimeUnixNano uint64
	// TimeUnixNano is required, see the detailed comments above Metric.
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	TimeUnixNano uint64
	// The number of values in the population. Must be
	// non-negative. This value must be equal to the sum of the "bucket_counts"
	// values in the positive and negative Buckets plus the "zero_count" field.
	Count uint64
	// The sum of the values in the population. If count is zero then this field
	// must be zero.
	//
	// Note: Sum should only be filled out when measuring non-negative discrete
	// events, and is assumed to be monotonic over the values of these events.
	// Negative events *can* be recorded, but sum should not be filled out when
	// doing so.  This is specifically to enforce compatibility w/ OpenMetrics,
	// see: https://github.com/prometheus/OpenMetrics/blob/v1.0.0/specification/OpenMetrics.md#histogram
	Sum *float64
	// scale describes the resolution of the histogram.  Boundaries are
	// located at powers of the base, where:
	//
	//	base = (2^(2^-scale))
	//
	// The histogram bucket identified by `index`, a signed integer,
	// contains values that are greater than (base^index) and
	// less than or equal to (base^(index+1)).
	//
	// The positive and negative ranges of the histogram are expressed
	// separately.  Negative values are mapped by their absolute value
	// into the negative range using the same scale as the positive range.
	//
	// scale is not restricted by the protocol, as the permissible
	// values depend on the range of the data.
	Scale int32
	// The count of values that are either exactly zero or
	// within the region considered zero by the instrumentation at the
	// tolerated degree of precision.  This bucket stores values that
	// cannot be expressed using the standard exponential formula as
	// well as values that have been rounded to zero.
	//
	// Implementations MAY consider the zero bucket to have probability
	// mass equal to (zero_count / count).
	ZeroCount uint64
	// positive carries the positive range of exponential bucket counts.
	Positive *ExponentialHistogramDataPoint_Buckets
	// negative carries the negative range of exponential bucket counts.
	Negative *ExponentialHistogramDataPoint_Buckets
	// Flags that apply to this specific data point.  See DataPointFlags
	// for the available flags and their meaning.
	Flags uint32
	// (Optional) List of exemplars collected from
	// measurements that were used to form the data point
	Exemplars []*Exemplar
	// The minimum value over (start_time, end_time].
	Min *float64
	// The maximum value over (start_time, end_time].
	Max *float64
	// ZeroThreshold may be optionally set to convey the width of the zero
	// region. Where the zero region is defined as the closed interval
	// [-ZeroThreshold, ZeroThreshold].
	// When ZeroThreshold is 0, zero count bucket stores values that cannot be
	// expressed using the standard exponential formula as well as values that
	// have been rounded to zero.
	ZeroThreshold float64
}

func (b0 ExponentialHistogramDataPoint_builder) Build() *ExponentialHistogramDataPoint {
	m0 := &ExponentialHistogramDataPoint{}
	b, x := &b0, m0
	_, _ = b, x
	x.xxx_hidden_Attributes = &b.Attributes
	x.xxx_hidden_StartTimeUnixNano = b.StartTimeUnixNano
	x.xxx_hidden_TimeUnixNano = b.TimeUnixNano
	x.xxx_hidden_Count = b.Count
	if b.Sum != nil {
		protoimpl.X.SetPresentNonAtomic(&(x.XXX_presence[0]), 4, 14)
		x.xxx_hidden_Sum = *b.Sum
	}
	x.xxx_hidden_Scale = b.Scale
	x.xxx_hidden_ZeroCount = b.ZeroCount
	x.xxx_hidden_Positive = b.Positive
	x.xxx_hidden_Negative = b.Negative
	x.xxx_hidden_Flags = b.Flags
	x.xxx_hidden_Exemplars = &b.Exemplars
	if b.Min != nil {
		protoimpl.X.SetPresentNonAtomic(&(x.XXX_presence[0]), 11, 14)
		x.xxx_hidden_Min = *b.Min
	}
	if b.Max != nil {
		protoimpl.X.SetPresentNonAtomic(&(x.XXX_presence[0]), 12, 14)
		x.xxx_hidden_Max = *b.Max
	}
	x.xxx_hidden_ZeroThreshold = b.ZeroThreshold
	return m0
}

// SummaryDataPoint is a single data point in a timeseries that describes the
// time-varying values of a Summary metric. The count and sum fields represent
// cumulative values.
type SummaryDataPoint struct {
	state                        protoimpl.MessageState               `protogen:"opaque.v1"`
	xxx_hidden_Attributes        *[]*v11.KeyValue                     `protobuf:"bytes,7,rep,name=attributes,proto3"`
	xxx_hidden_StartTimeUnixNano uint64                               `protobuf:"fixed64,2,opt,name=start_time_unix_nano,json=startTimeUnixNano,proto3"`
	xxx_hidden_TimeUnixNano      uint64                               `protobuf:"fixed64,3,opt,name=time_unix_nano,json=timeUnixNano,proto3"`
	xxx_hidden_Count             uint64                               `protobuf:"fixed64,4,opt,name=count,proto3"`
	xxx_hidden_Sum               float64                              `protobuf:"fixed64,5,opt,name=sum,proto3"`
	xxx_hidden_QuantileValues    *[]*SummaryDataPoint_ValueAtQuantile `protobuf:"bytes,6,rep,name=quantile_values,json=quantileValues,proto3"`
	xxx_hidden_Flags             uint32                               `protobuf:"varint,8,opt,name=flags,proto3"`
	unknownFields                protoimpl.UnknownFields
	sizeCache                    protoimpl.SizeCache
}

func (x *SummaryDataPoint) Reset() {
	*x = SummaryDataPoint{}
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[12]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SummaryDataPoint) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SummaryDataPoint) ProtoMessage() {}

func (x *SummaryDataPoint) ProtoReflect() protoreflect.Message {
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[12]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *SummaryDataPoint) GetAttributes() []*v11.KeyValue {
	if x != nil {
		if x.xxx_hidden_Attributes != nil {
			return *x.xxx_hidden_Attributes
		}
	}
	return nil
}

func (x *SummaryDataPoint) GetStartTimeUnixNano() uint64 {
	if x != nil {
		return x.xxx_hidden_StartTimeUnixNano
	}
	return 0
}

func (x *SummaryDataPoint) GetTimeUnixNano() uint64 {
	if x != nil {
		return x.xxx_hidden_TimeUnixNano
	}
	return 0
}

func (x *SummaryDataPoint) GetCount() uint64 {
	if x != nil {
		return x.xxx_hidden_Count
	}
	return 0
}

func (x *SummaryDataPoint) GetSum() float64 {
	if x != nil {
		return x.xxx_hidden_Sum
	}
	return 0
}

func (x *SummaryDataPoint) GetQuantileValues() []*SummaryDataPoint_ValueAtQuantile {
	if x != nil {
		if x.xxx_hidden_QuantileValues != nil {
			return *x.xxx_hidden_QuantileValues
		}
	}
	return nil
}

func (x *SummaryDataPoint) GetFlags() uint32 {
	if x != nil {
		return x.xxx_hidden_Flags
	}
	return 0
}

func (x *SummaryDataPoint) SetAttributes(v []*v11.KeyValue) {
	x.xxx_hidden_Attributes = &v
}

func (x *SummaryDataPoint) SetStartTimeUnixNano(v uint64) {
	x.xxx_hidden_StartTimeUnixNano = v
}

func (x *SummaryDataPoint) SetTimeUnixNano(v uint64) {
	x.xxx_hidden_TimeUnixNano = v
}

func (x *SummaryDataPoint) SetCount(v uint64) {
	x.xxx_hidden_Count = v
}

func (x *SummaryDataPoint) SetSum(v float64) {
	x.xxx_hidden_Sum = v
}

func (x *SummaryDataPoint) SetQuantileValues(v []*SummaryDataPoint_ValueAtQuantile) {
	x.xxx_hidden_QuantileValues = &v
}

func (x *SummaryDataPoint) SetFlags(v uint32) {
	x.xxx_hidden_Flags = v
}

type SummaryDataPoint_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The set of key/value pairs that uniquely identify the timeseries from
	// where this point belongs. The list may be empty (may contain 0 elements).
	// Attribute keys MUST be unique (it is not allowed to have more than one
	// attribute with the same key).
	// The behavior of software that receives duplicated keys can be unpredictable.
	Attributes []*v11.KeyValue
	// StartTimeUnixNano is optional but strongly encouraged, see the
	// the detailed comments above Metric.
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	StartTimeUnixNano uint64
	// TimeUnixNano is required, see the detailed comments above Metric.
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	TimeUnixNano uint64
	// count is the number of values in the population. Must be non-negative.
	Count uint64
	// sum of the values in the population. If count is zero then this field
	// must be zero.
	//
	// Note: Sum should only be filled out when measuring non-negative discrete
	// events, and is assumed to be monotonic over the values of these events.
	// Negative events *can* be recorded, but sum should not be filled out when
	// doing so.  This is specifically to enforce compatibility w/ OpenMetrics,
	// see: https://github.com/prometheus/OpenMetrics/blob/v1.0.0/specification/OpenMetrics.md#summary
	Sum float64
	// (Optional) list of values at different quantiles of the distribution calculated
	// from the current snapshot. The quantiles must be strictly increasing.
	QuantileValues []*SummaryDataPoint_ValueAtQuantile
	// Flags that apply to this specific data point.  See DataPointFlags
	// for the available flags and their meaning.
	Flags uint32
}

func (b0 SummaryDataPoint_builder) Build() *SummaryDataPoint {
	m0 := &SummaryDataPoint{}
	b, x := &b0, m0
	_, _ = b, x
	x.xxx_hidden_Attributes = &b.Attributes
	x.xxx_hidden_StartTimeUnixNano = b.StartTimeUnixNano
	x.xxx_hidden_TimeUnixNano = b.TimeUnixNano
	x.xxx_hidden_Count = b.Count
	x.xxx_hidden_Sum = b.Sum
	x.xxx_hidden_QuantileValues = &b.QuantileValues
	x.xxx_hidden_Flags = b.Flags
	return m0
}

// A representation of an exemplar, which is a sample input measurement.
// Exemplars also hold information about the environment when the measurement
// was recorded, for example the span and trace ID of the active span when the
// exemplar was recorded.
type Exemplar struct {
	state                         protoimpl.MessageState `protogen:"opaque.v1"`
	xxx_hidden_FilteredAttributes *[]*v11.KeyValue       `protobuf:"bytes,7,rep,name=filtered_attributes,json=filteredAttributes,proto3"`
	xxx_hidden_TimeUnixNano       uint64                 `protobuf:"fixed64,2,opt,name=time_unix_nano,json=timeUnixNano,proto3"`
	xxx_hidden_Value              isExemplar_Value       `protobuf_oneof:"value"`
	xxx_hidden_SpanId             []byte                 `protobuf:"bytes,4,opt,name=span_id,json=spanId,proto3"`
	xxx_hidden_TraceId            []byte                 `protobuf:"bytes,5,opt,name=trace_id,json=traceId,proto3"`
	unknownFields                 protoimpl.UnknownFields
	sizeCache                     protoimpl.SizeCache
}

func (x *Exemplar) Reset() {
	*x = Exemplar{}
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[13]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Exemplar) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Exemplar) ProtoMessage() {}

func (x *Exemplar) ProtoReflect() protoreflect.Message {
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[13]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *Exemplar) GetFilteredAttributes() []*v11.KeyValue {
	if x != nil {
		if x.xxx_hidden_FilteredAttributes != nil {
			return *x.xxx_hidden_FilteredAttributes
		}
	}
	return nil
}

func (x *Exemplar) GetTimeUnixNano() uint64 {
	if x != nil {
		return x.xxx_hidden_TimeUnixNano
	}
	return 0
}

func (x *Exemplar) GetAsDouble() float64 {
	if x != nil {
		if x, ok := x.xxx_hidden_Value.(*exemplar_AsDouble); ok {
			return x.AsDouble
		}
	}
	return 0
}

func (x *Exemplar) GetAsInt() int64 {
	if x != nil {
		if x, ok := x.xxx_hidden_Value.(*exemplar_AsInt); ok {
			return x.AsInt
		}
	}
	return 0
}

func (x *Exemplar) GetSpanId() []byte {
	if x != nil {
		return x.xxx_hidden_SpanId
	}
	return nil
}

func (x *Exemplar) GetTraceId() []byte {
	if x != nil {
		return x.xxx_hidden_TraceId
	}
	return nil
}

func (x *Exemplar) SetFilteredAttributes(v []*v11.KeyValue) {
	x.xxx_hidden_FilteredAttributes = &v
}

func (x *Exemplar) SetTimeUnixNano(v uint64) {
	x.xxx_hidden_TimeUnixNano = v
}

func (x *Exemplar) SetAsDouble(v float64) {
	x.xxx_hidden_Value = &exemplar_AsDouble{v}
}

func (x *Exemplar) SetAsInt(v int64) {
	x.xxx_hidden_Value = &exemplar_AsInt{v}
}

func (x *Exemplar) SetSpanId(v []byte) {
	if v == nil {
		v = []byte{}
	}
	x.xxx_hidden_SpanId = v
}

func (x *Exemplar) SetTraceId(v []byte) {
	if v == nil {
		v = []byte{}
	}
	x.xxx_hidden_TraceId = v
}

func (x *Exemplar) HasValue() bool {
	if x == nil {
		return false
	}
	return x.xxx_hidden_Value != nil
}

func (x *Exemplar) HasAsDouble() bool {
	if x == nil {
		return false
	}
	_, ok := x.xxx_hidden_Value.(*exemplar_AsDouble)
	return ok
}

func (x *Exemplar) HasAsInt() bool {
	if x == nil {
		return false
	}
	_, ok := x.xxx_hidden_Value.(*exemplar_AsInt)
	return ok
}

func (x *Exemplar) ClearValue() {
	x.xxx_hidden_Value = nil
}

func (x *Exemplar) ClearAsDouble() {
	if _, ok := x.xxx_hidden_Value.(*exemplar_AsDouble); ok {
		x.xxx_hidden_Value = nil
	}
}

func (x *Exemplar) ClearAsInt() {
	if _, ok := x.xxx_hidden_Value.(*exemplar_AsInt); ok {
		x.xxx_hidden_Value = nil
	}
}

const Exemplar_Value_not_set_case case_Exemplar_Value = 0
const Exemplar_AsDouble_case case_Exemplar_Value = 3
const Exemplar_AsInt_case case_Exemplar_Value = 6

func (x *Exemplar) WhichValue() case_Exemplar_Value {
	if x == nil {
		return Exemplar_Value_not_set_case
	}
	switch x.xxx_hidden_Value.(type) {
	case *exemplar_AsDouble:
		return Exemplar_AsDouble_case
	case *exemplar_AsInt:
		return Exemplar_AsInt_case
	default:
		return Exemplar_Value_not_set_case
	}
}

type Exemplar_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The set of key/value pairs that were filtered out by the aggregator, but
	// recorded alongside the original measurement. Only key/value pairs that were
	// filtered out by the aggregator should be included
	FilteredAttributes []*v11.KeyValue
	// time_unix_nano is the exact time when this exemplar was recorded
	//
	// Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
	// 1970.
	TimeUnixNano uint64
	// The value of the measurement that was recorded. An exemplar is
	// considered invalid when one of the recognized value fields is not present
	// inside this oneof.

	// Fields of oneof xxx_hidden_Value:
	AsDouble *float64
	AsInt    *int64
	// -- end of xxx_hidden_Value
	// (Optional) Span ID of the exemplar trace.
	// span_id may be missing if the measurement is not recorded inside a trace
	// or if the trace is not sampled.
	SpanId []byte
	// (Optional) Trace ID of the exemplar trace.
	// trace_id may be missing if the measurement is not recorded inside a trace
	// or if the trace is not sampled.
	TraceId []byte
}

func (b0 Exemplar_builder) Build() *Exemplar {
	m0 := &Exemplar{}
	b, x := &b0, m0
	_, _ = b, x
	x.xxx_hidden_FilteredAttributes = &b.FilteredAttributes
	x.xxx_hidden_TimeUnixNano = b.TimeUnixNano
	if b.AsDouble != nil {
		x.xxx_hidden_Value = &exemplar_AsDouble{*b.AsDouble}
	}
	if b.AsInt != nil {
		x.xxx_hidden_Value = &exemplar_AsInt{*b.AsInt}
	}
	x.xxx_hidden_SpanId = b.SpanId
	x.xxx_hidden_TraceId = b.TraceId
	return m0
}

type case_Exemplar_Value protoreflect.FieldNumber

func (x case_Exemplar_Value) String() string {
	md := file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[13].Descriptor()
	if x == 0 {
		return "not set"
	}
	return protoimpl.X.MessageFieldStringOf(md, protoreflect.FieldNumber(x))
}

type isExemplar_Value interface {
	isExemplar_Value()
}

type exemplar_AsDouble struct {
	AsDouble float64 `protobuf:"fixed64,3,opt,name=as_double,json=asDouble,proto3,oneof"`
}

type exemplar_AsInt struct {
	AsInt int64 `protobuf:"fixed64,6,opt,name=as_int,json=asInt,proto3,oneof"`
}

func (*exemplar_AsDouble) isExemplar_Value() {}

func (*exemplar_AsInt) isExemplar_Value() {}

// Buckets are a set of bucket counts, encoded in a contiguous array
// of counts.
type ExponentialHistogramDataPoint_Buckets struct {
	state                   protoimpl.MessageState `protogen:"opaque.v1"`
	xxx_hidden_Offset       int32                  `protobuf:"zigzag32,1,opt,name=offset,proto3"`
	xxx_hidden_BucketCounts []uint64               `protobuf:"varint,2,rep,packed,name=bucket_counts,json=bucketCounts,proto3"`
	unknownFields           protoimpl.UnknownFields
	sizeCache               protoimpl.SizeCache
}

func (x *ExponentialHistogramDataPoint_Buckets) Reset() {
	*x = ExponentialHistogramDataPoint_Buckets{}
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[14]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ExponentialHistogramDataPoint_Buckets) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ExponentialHistogramDataPoint_Buckets) ProtoMessage() {}

func (x *ExponentialHistogramDataPoint_Buckets) ProtoReflect() protoreflect.Message {
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[14]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *ExponentialHistogramDataPoint_Buckets) GetOffset() int32 {
	if x != nil {
		return x.xxx_hidden_Offset
	}
	return 0
}

func (x *ExponentialHistogramDataPoint_Buckets) GetBucketCounts() []uint64 {
	if x != nil {
		return x.xxx_hidden_BucketCounts
	}
	return nil
}

func (x *ExponentialHistogramDataPoint_Buckets) SetOffset(v int32) {
	x.xxx_hidden_Offset = v
}

func (x *ExponentialHistogramDataPoint_Buckets) SetBucketCounts(v []uint64) {
	x.xxx_hidden_BucketCounts = v
}

type ExponentialHistogramDataPoint_Buckets_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The bucket index of the first entry in the bucket_counts array.
	//
	// Note: This uses a varint encoding as a simple form of compression.
	Offset int32
	// An array of count values, where bucket_counts[i] carries
	// the count of the bucket at index (offset+i). bucket_counts[i] is the count
	// of values greater than base^(offset+i) and less than or equal to
	// base^(offset+i+1).
	//
	// Note: By contrast, the explicit HistogramDataPoint uses
	// fixed64.  This field is expected to have many buckets,
	// especially zeros, so uint64 has been selected to ensure
	// varint encoding.
	BucketCounts []uint64
}

func (b0 ExponentialHistogramDataPoint_Buckets_builder) Build() *ExponentialHistogramDataPoint_Buckets {
	m0 := &ExponentialHistogramDataPoint_Buckets{}
	b, x := &b0, m0
	_, _ = b, x
	x.xxx_hidden_Offset = b.Offset
	x.xxx_hidden_BucketCounts = b.BucketCounts
	return m0
}

// Represents the value at a given quantile of a distribution.
//
// To record Min and Max values following conventions are used:
// - The 1.0 quantile is equivalent to the maximum value observed.
// - The 0.0 quantile is equivalent to the minimum value observed.
//
// See the following issue for more context:
// https://github.com/open-telemetry/opentelemetry-proto/issues/125
type SummaryDataPoint_ValueAtQuantile struct {
	state               protoimpl.MessageState `protogen:"opaque.v1"`
	xxx_hidden_Quantile float64                `protobuf:"fixed64,1,opt,name=quantile,proto3"`
	xxx_hidden_Value    float64                `protobuf:"fixed64,2,opt,name=value,proto3"`
	unknownFields       protoimpl.UnknownFields
	sizeCache           protoimpl.SizeCache
}

func (x *SummaryDataPoint_ValueAtQuantile) Reset() {
	*x = SummaryDataPoint_ValueAtQuantile{}
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[15]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SummaryDataPoint_ValueAtQuantile) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SummaryDataPoint_ValueAtQuantile) ProtoMessage() {}

func (x *SummaryDataPoint_ValueAtQuantile) ProtoReflect() protoreflect.Message {
	mi := &file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[15]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *SummaryDataPoint_ValueAtQuantile) GetQuantile() float64 {
	if x != nil {
		return x.xxx_hidden_Quantile
	}
	return 0
}

func (x *SummaryDataPoint_ValueAtQuantile) GetValue() float64 {
	if x != nil {
		return x.xxx_hidden_Value
	}
	return 0
}

func (x *SummaryDataPoint_ValueAtQuantile) SetQuantile(v float64) {
	x.xxx_hidden_Quantile = v
}

func (x *SummaryDataPoint_ValueAtQuantile) SetValue(v float64) {
	x.xxx_hidden_Value = v
}

type SummaryDataPoint_ValueAtQuantile_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The quantile of a distribution. Must be in the interval
	// [0.0, 1.0].
	Quantile float64
	// The value at the given quantile of a distribution.
	//
	// Quantile values must NOT be negative.
	Value float64
}

func (b0 SummaryDataPoint_ValueAtQuantile_builder) Build() *SummaryDataPoint_ValueAtQuantile {
	m0 := &SummaryDataPoint_ValueAtQuantile{}
	b, x := &b0, m0
	_, _ = b, x
	x.xxx_hidden_Quantile = b.Quantile
	x.xxx_hidden_Value = b.Value
	return m0
}

var File_opentelemetry_proto_metrics_v1_metrics_proto protoreflect.FileDescriptor

const file_opentelemetry_proto_metrics_v1_metrics_proto_rawDesc = "" +
	"\n" +
	",opentelemetry/proto/metrics/v1/metrics.proto\x12\x1eopentelemetry.proto.metrics.v1\x1a*opentelemetry/proto/common/v1/common.proto\x1a.opentelemetry/proto/resource/v1/resource.proto\"i\n" +
	"\vMetricsData\x12Z\n" +
	"\x10resource_metrics\x18\x01 \x03(\v2/.opentelemetry.proto.metrics.v1.ResourceMetricsR\x0fresourceMetrics\"\xd2\x01\n" +
	"\x0fResourceMetrics\x12E\n" +
	"\bresource\x18\x01 \x01(\v2).opentelemetry.proto.resource.v1.ResourceR\bresource\x12Q\n" +
	"\rscope_metrics\x18\x02 \x03(\v2,.opentelemetry.proto.metrics.v1.ScopeMetricsR\fscopeMetrics\x12\x1d\n" +
	"\n" +
	"schema_url\x18\x03 \x01(\tR\tschemaUrlJ\x06\b\xe8\a\x10\xe9\a\"\xba\x01\n" +
	"\fScopeMetrics\x12I\n" +
	"\x05scope\x18\x01 \x01(\v23.opentelemetry.proto.common.v1.InstrumentationScopeR\x05scope\x12@\n" +
	"\ametrics\x18\x02 \x03(\v2&.opentelemetry.proto.metrics.v1.MetricR\ametrics\x12\x1d\n" +
	"\n" +
	"schema_url\x18\x03 \x01(\tR\tschemaUrl\"\xa6\x04\n" +
	"\x06Metric\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12 \n" +
	"\vdescription\x18\x02 \x01(\tR\vdescription\x12\x12\n" +
	"\x04unit\x18\x03 \x01(\tR\x04unit\x12=\n" +
	"\x05gauge\x18\x05 \x01(\v2%.opentelemetry.proto.metrics.v1.GaugeH\x00R\x05gauge\x127\n" +
	"\x03sum\x18\a \x01(\v2#.opentelemetry.proto.metrics.v1.SumH\x00R\x03sum\x12I\n" +
	"\thistogram\x18\t \x01(\v2).opentelemetry.proto.metrics.v1.HistogramH\x00R\thistogram\x12k\n" +
	"\x15exponential_histogram\x18\n" +
	" \x01(\v24.opentelemetry.proto.metrics.v1.ExponentialHistogramH\x00R\x14exponentialHistogram\x12C\n" +
	"\asummary\x18\v \x01(\v2'.opentelemetry.proto.metrics.v1.SummaryH\x00R\asummary\x12C\n" +
	"\bmetadata\x18\f \x03(\v2'.opentelemetry.proto.common.v1.KeyValueR\bmetadataB\x06\n" +
	"\x04dataJ\x04\b\x04\x10\x05J\x04\b\x06\x10\aJ\x04\b\b\x10\t\"Y\n" +
	"\x05Gauge\x12P\n" +
	"\vdata_points\x18\x01 \x03(\v2/.opentelemetry.proto.metrics.v1.NumberDataPointR\n" +
	"dataPoints\"\xeb\x01\n" +
	"\x03Sum\x12P\n" +
	"\vdata_points\x18\x01 \x03(\v2/.opentelemetry.proto.metrics.v1.NumberDataPointR\n" +
	"dataPoints\x12o\n" +
	"\x17aggregation_temporality\x18\x02 \x01(\x0e26.opentelemetry.proto.metrics.v1.AggregationTemporalityR\x16aggregationTemporality\x12!\n" +
	"\fis_monotonic\x18\x03 \x01(\bR\visMonotonic\"\xd1\x01\n" +
	"\tHistogram\x12S\n" +
	"\vdata_points\x18\x01 \x03(\v22.opentelemetry.proto.metrics.v1.HistogramDataPointR\n" +
	"dataPoints\x12o\n" +
	"\x17aggregation_temporality\x18\x02 \x01(\x0e26.opentelemetry.proto.metrics.v1.AggregationTemporalityR\x16aggregationTemporality\"\xe7\x01\n" +
	"\x14ExponentialHistogram\x12^\n" +
	"\vdata_points\x18\x01 \x03(\v2=.opentelemetry.proto.metrics.v1.ExponentialHistogramDataPointR\n" +
	"dataPoints\x12o\n" +
	"\x17aggregation_temporality\x18\x02 \x01(\x0e26.opentelemetry.proto.metrics.v1.AggregationTemporalityR\x16aggregationTemporality\"\\\n" +
	"\aSummary\x12Q\n" +
	"\vdata_points\x18\x01 \x03(\v20.opentelemetry.proto.metrics.v1.SummaryDataPointR\n" +
	"dataPoints\"\xd6\x02\n" +
	"\x0fNumberDataPoint\x12G\n" +
	"\n" +
	"attributes\x18\a \x03(\v2'.opentelemetry.proto.common.v1.KeyValueR\n" +
	"attributes\x12/\n" +
	"\x14start_time_unix_nano\x18\x02 \x01(\x06R\x11startTimeUnixNano\x12$\n" +
	"\x0etime_unix_nano\x18\x03 \x01(\x06R\ftimeUnixNano\x12\x1d\n" +
	"\tas_double\x18\x04 \x01(\x01H\x00R\basDouble\x12\x17\n" +
	"\x06as_int\x18\x06 \x01(\x10H\x00R\x05asInt\x12F\n" +
	"\texemplars\x18\x05 \x03(\v2(.opentelemetry.proto.metrics.v1.ExemplarR\texemplars\x12\x14\n" +
	"\x05flags\x18\b \x01(\rR\x05flagsB\a\n" +
	"\x05valueJ\x04\b\x01\x10\x02\"\xd9\x03\n" +
	"\x12HistogramDataPoint\x12G\n" +
	"\n" +
	"attributes\x18\t \x03(\v2'.opentelemetry.proto.common.v1.KeyValueR\n" +
	"attributes\x12/\n" +
	"\x14start_time_unix_nano\x18\x02 \x01(\x06R\x11startTimeUnixNano\x12$\n" +
	"\x0etime_unix_nano\x18\x03 \x01(\x06R\ftimeUnixNano\x12\x14\n" +
	"\x05count\x18\x04 \x01(\x06R\x05count\x12\x15\n" +
	"\x03sum\x18\x05 \x01(\x01H\x00R\x03sum\x88\x01\x01\x12#\n" +
	"\rbucket_counts\x18\x06 \x03(\x06R\fbucketCounts\x12'\n" +
	"\x0fexplicit_bounds\x18\a \x03(\x01R\x0eexplicitBounds\x12F\n" +
	"\texemplars\x18\b \x03(\v2(.opentelemetry.proto.metrics.v1.ExemplarR\texemplars\x12\x14\n" +
	"\x05flags\x18\n" +
	" \x01(\rR\x05flags\x12\x15\n" +
	"\x03min\x18\v \x01(\x01H\x01R\x03min\x88\x01\x01\x12\x15\n" +
	"\x03max\x18\f \x01(\x01H\x02R\x03max\x88\x01\x01B\x06\n" +
	"\x04_sumB\x06\n" +
	"\x04_minB\x06\n" +
	"\x04_maxJ\x04\b\x01\x10\x02\"\xfa\x05\n" +
	"\x1dExponentialHistogramDataPoint\x12G\n" +
	"\n" +
	"attributes\x18\x01 \x03(\v2'.opentelemetry.proto.common.v1.KeyValueR\n" +
	"attributes\x12/\n" +
	"\x14start_time_unix_nano\x18\x02 \x01(\x06R\x11startTimeUnixNano\x12$\n" +
	"\x0etime_unix_nano\x18\x03 \x01(\x06R\ftimeUnixNano\x12\x14\n" +
	"\x05count\x18\x04 \x01(\x06R\x05count\x12\x15\n" +
	"\x03sum\x18\x05 \x01(\x01H\x00R\x03sum\x88\x01\x01\x12\x14\n" +
	"\x05scale\x18\x06 \x01(\x11R\x05scale\x12\x1d\n" +
	"\n" +
	"zero_count\x18\a \x01(\x06R\tzeroCount\x12a\n" +
	"\bpositive\x18\b \x01(\v2E.opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint.BucketsR\bpositive\x12a\n" +
	"\bnegative\x18\t \x01(\v2E.opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint.BucketsR\bnegative\x12\x14\n" +
	"\x05flags\x18\n" +
	" \x01(\rR\x05flags\x12F\n" +
	"\texemplars\x18\v \x03(\v2(.opentelemetry.proto.metrics.v1.ExemplarR\texemplars\x12\x15\n" +
	"\x03min\x18\f \x01(\x01H\x01R\x03min\x88\x01\x01\x12\x15\n" +
	"\x03max\x18\r \x01(\x01H\x02R\x03max\x88\x01\x01\x12%\n" +
	"\x0ezero_threshold\x18\x0e \x01(\x01R\rzeroThreshold\x1aF\n" +
	"\aBuckets\x12\x16\n" +
	"\x06offset\x18\x01 \x01(\x11R\x06offset\x12#\n" +
	"\rbucket_counts\x18\x02 \x03(\x04R\fbucketCountsB\x06\n" +
	"\x04_sumB\x06\n" +
	"\x04_minB\x06\n" +
	"\x04_max\"\xa6\x03\n" +
	"\x10SummaryDataPoint\x12G\n" +
	"\n" +
	"attributes\x18\a \x03(\v2'.opentelemetry.proto.common.v1.KeyValueR\n" +
	"attributes\x12/\n" +
	"\x14start_time_unix_nano\x18\x02 \x01(\x06R\x11startTimeUnixNano\x12$\n" +
	"\x0etime_unix_nano\x18\x03 \x01(\x06R\ftimeUnixNano\x12\x14\n" +
	"\x05count\x18\x04 \x01(\x06R\x05count\x12\x10\n" +
	"\x03sum\x18\x05 \x01(\x01R\x03sum\x12i\n" +
	"\x0fquantile_values\x18\x06 \x03(\v2@.opentelemetry.proto.metrics.v1.SummaryDataPoint.ValueAtQuantileR\x0equantileValues\x12\x14\n" +
	"\x05flags\x18\b \x01(\rR\x05flags\x1aC\n" +
	"\x0fValueAtQuantile\x12\x1a\n" +
	"\bquantile\x18\x01 \x01(\x01R\bquantile\x12\x14\n" +
	"\x05value\x18\x02 \x01(\x01R\x05valueJ\x04\b\x01\x10\x02\"\x85\x02\n" +
	"\bExemplar\x12X\n" +
	"\x13filtered_attributes\x18\a \x03(\v2'.opentelemetry.proto.common.v1.KeyValueR\x12filteredAttributes\x12$\n" +
	"\x0etime_unix_nano\x18\x02 \x01(\x06R\ftimeUnixNano\x12\x1d\n" +
	"\tas_double\x18\x03 \x01(\x01H\x00R\basDouble\x12\x17\n" +
	"\x06as_int\x18\x06 \x01(\x10H\x00R\x05asInt\x12\x17\n" +
	"\aspan_id\x18\x04 \x01(\fR\x06spanId\x12\x19\n" +
	"\btrace_id\x18\x05 \x01(\fR\atraceIdB\a\n" +
	"\x05valueJ\x04\b\x01\x10\x02*\x8c\x01\n" +
	"\x16AggregationTemporality\x12'\n" +
	"#AGGREGATION_TEMPORALITY_UNSPECIFIED\x10\x00\x12!\n" +
	"\x1dAGGREGATION_TEMPORALITY_DELTA\x10\x01\x12&\n" +
	"\"AGGREGATION_TEMPORALITY_CUMULATIVE\x10\x02*^\n" +
	"\x0eDataPointFlags\x12\x1f\n" +
	"\x1bDATA_POINT_FLAGS_DO_NOT_USE\x10\x00\x12+\n" +
	"'DATA_POINT_FLAGS_NO_RECORDED_VALUE_MASK\x10\x01B\xbe\x01\n" +
	"!io.opentelemetry.proto.metrics.v1B\fMetricsProtoP\x01Zhbuf.build/gen/go/opentelemetry/opentelemetry/protocolbuffers/go/opentelemetry/proto/metrics/v1;metricsv1\xaa\x02\x1eOpenTelemetry.Proto.Metrics.V1b\x06proto3"

var file_opentelemetry_proto_metrics_v1_metrics_proto_enumTypes = make([]protoimpl.EnumInfo, 2)
var file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes = make([]protoimpl.MessageInfo, 16)
var file_opentelemetry_proto_metrics_v1_metrics_proto_goTypes = []any{
	(AggregationTemporality)(0),                   // 0: opentelemetry.proto.metrics.v1.AggregationTemporality
	(DataPointFlags)(0),                           // 1: opentelemetry.proto.metrics.v1.DataPointFlags
	(*MetricsData)(nil),                           // 2: opentelemetry.proto.metrics.v1.MetricsData
	(*ResourceMetrics)(nil),                       // 3: opentelemetry.proto.metrics.v1.ResourceMetrics
	(*ScopeMetrics)(nil),                          // 4: opentelemetry.proto.metrics.v1.ScopeMetrics
	(*Metric)(nil),                                // 5: opentelemetry.proto.metrics.v1.Metric
	(*Gauge)(nil),                                 // 6: opentelemetry.proto.metrics.v1.Gauge
	(*Sum)(nil),                                   // 7: opentelemetry.proto.metrics.v1.Sum
	(*Histogram)(nil),                             // 8: opentelemetry.proto.metrics.v1.Histogram
	(*ExponentialHistogram)(nil),                  // 9: opentelemetry.proto.metrics.v1.ExponentialHistogram
	(*Summary)(nil),                               // 10: opentelemetry.proto.metrics.v1.Summary
	(*NumberDataPoint)(nil),                       // 11: opentelemetry.proto.metrics.v1.NumberDataPoint
	(*HistogramDataPoint)(nil),                    // 12: opentelemetry.proto.metrics.v1.HistogramDataPoint
	(*ExponentialHistogramDataPoint)(nil),         // 13: opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint
	(*SummaryDataPoint)(nil),                      // 14: opentelemetry.proto.metrics.v1.SummaryDataPoint
	(*Exemplar)(nil),                              // 15: opentelemetry.proto.metrics.v1.Exemplar
	(*ExponentialHistogramDataPoint_Buckets)(nil), // 16: opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint.Buckets
	(*SummaryDataPoint_ValueAtQuantile)(nil),      // 17: opentelemetry.proto.metrics.v1.SummaryDataPoint.ValueAtQuantile
	(*v1.Resource)(nil),                           // 18: opentelemetry.proto.resource.v1.Resource
	(*v11.InstrumentationScope)(nil),              // 19: opentelemetry.proto.common.v1.InstrumentationScope
	(*v11.KeyValue)(nil),                          // 20: opentelemetry.proto.common.v1.KeyValue
}
var file_opentelemetry_proto_metrics_v1_metrics_proto_depIdxs = []int32{
	3,  // 0: opentelemetry.proto.metrics.v1.MetricsData.resource_metrics:type_name -> opentelemetry.proto.metrics.v1.ResourceMetrics
	18, // 1: opentelemetry.proto.metrics.v1.ResourceMetrics.resource:type_name -> opentelemetry.proto.resource.v1.Resource
	4,  // 2: opentelemetry.proto.metrics.v1.ResourceMetrics.scope_metrics:type_name -> opentelemetry.proto.metrics.v1.ScopeMetrics
	19, // 3: opentelemetry.proto.metrics.v1.ScopeMetrics.scope:type_name -> opentelemetry.proto.common.v1.InstrumentationScope
	5,  // 4: opentelemetry.proto.metrics.v1.ScopeMetrics.metrics:type_name -> opentelemetry.proto.metrics.v1.Metric
	6,  // 5: opentelemetry.proto.metrics.v1.Metric.gauge:type_name -> opentelemetry.proto.metrics.v1.Gauge
	7,  // 6: opentelemetry.proto.metrics.v1.Metric.sum:type_name -> opentelemetry.proto.metrics.v1.Sum
	8,  // 7: opentelemetry.proto.metrics.v1.Metric.histogram:type_name -> opentelemetry.proto.metrics.v1.Histogram
	9,  // 8: opentelemetry.proto.metrics.v1.Metric.exponential_histogram:type_name -> opentelemetry.proto.metrics.v1.ExponentialHistogram
	10, // 9: opentelemetry.proto.metrics.v1.Metric.summary:type_name -> opentelemetry.proto.metrics.v1.Summary
	20, // 10: opentelemetry.proto.metrics.v1.Metric.metadata:type_name -> opentelemetry.proto.common.v1.KeyValue
	11, // 11: opentelemetry.proto.metrics.v1.Gauge.data_points:type_name -> opentelemetry.proto.metrics.v1.NumberDataPoint
	11, // 12: opentelemetry.proto.metrics.v1.Sum.data_points:type_name -> opentelemetry.proto.metrics.v1.NumberDataPoint
	0,  // 13: opentelemetry.proto.metrics.v1.Sum.aggregation_temporality:type_name -> opentelemetry.proto.metrics.v1.AggregationTemporality
	12, // 14: opentelemetry.proto.metrics.v1.Histogram.data_points:type_name -> opentelemetry.proto.metrics.v1.HistogramDataPoint
	0,  // 15: opentelemetry.proto.metrics.v1.Histogram.aggregation_temporality:type_name -> opentelemetry.proto.metrics.v1.AggregationTemporality
	13, // 16: opentelemetry.proto.metrics.v1.ExponentialHistogram.data_points:type_name -> opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint
	0,  // 17: opentelemetry.proto.metrics.v1.ExponentialHistogram.aggregation_temporality:type_name -> opentelemetry.proto.metrics.v1.AggregationTemporality
	14, // 18: opentelemetry.proto.metrics.v1.Summary.data_points:type_name -> opentelemetry.proto.metrics.v1.SummaryDataPoint
	20, // 19: opentelemetry.proto.metrics.v1.NumberDataPoint.attributes:type_name -> opentelemetry.proto.common.v1.KeyValue
	15, // 20: opentelemetry.proto.metrics.v1.NumberDataPoint.exemplars:type_name -> opentelemetry.proto.metrics.v1.Exemplar
	20, // 21: opentelemetry.proto.metrics.v1.HistogramDataPoint.attributes:type_name -> opentelemetry.proto.common.v1.KeyValue
	15, // 22: opentelemetry.proto.metrics.v1.HistogramDataPoint.exemplars:type_name -> opentelemetry.proto.metrics.v1.Exemplar
	20, // 23: opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint.attributes:type_name -> opentelemetry.proto.common.v1.KeyValue
	16, // 24: opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint.positive:type_name -> opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint.Buckets
	16, // 25: opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint.negative:type_name -> opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint.Buckets
	15, // 26: opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint.exemplars:type_name -> opentelemetry.proto.metrics.v1.Exemplar
	20, // 27: opentelemetry.proto.metrics.v1.SummaryDataPoint.attributes:type_name -> opentelemetry.proto.common.v1.KeyValue
	17, // 28: opentelemetry.proto.metrics.v1.SummaryDataPoint.quantile_values:type_name -> opentelemetry.proto.metrics.v1.SummaryDataPoint.ValueAtQuantile
	20, // 29: opentelemetry.proto.metrics.v1.Exemplar.filtered_attributes:type_name -> opentelemetry.proto.common.v1.KeyValue
	30, // [30:30] is the sub-list for method output_type
	30, // [30:30] is the sub-list for method input_type
	30, // [30:30] is the sub-list for extension type_name
	30, // [30:30] is the sub-list for extension extendee
	0,  // [0:30] is the sub-list for field type_name
}

func init() { file_opentelemetry_proto_metrics_v1_metrics_proto_init() }
func file_opentelemetry_proto_metrics_v1_metrics_proto_init() {
	if File_opentelemetry_proto_metrics_v1_metrics_proto != nil {
		return
	}
	file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[3].OneofWrappers = []any{
		(*metric_Gauge)(nil),
		(*metric_Sum)(nil),
		(*metric_Histogram)(nil),
		(*metric_ExponentialHistogram)(nil),
		(*metric_Summary)(nil),
	}
	file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[9].OneofWrappers = []any{
		(*numberDataPoint_AsDouble)(nil),
		(*numberDataPoint_AsInt)(nil),
	}
	file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[10].OneofWrappers = []any{}
	file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[11].OneofWrappers = []any{}
	file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes[13].OneofWrappers = []any{
		(*exemplar_AsDouble)(nil),
		(*exemplar_AsInt)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_opentelemetry_proto_metrics_v1_metrics_proto_rawDesc), len(file_opentelemetry_proto_metrics_v1_metrics_proto_rawDesc)),
			NumEnums:      2,
			NumMessages:   16,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_opentelemetry_proto_metrics_v1_metrics_proto_goTypes,
		DependencyIndexes: file_opentelemetry_proto_metrics_v1_metrics_proto_depIdxs,
		EnumInfos:         file_opentelemetry_proto_metrics_v1_metrics_proto_enumTypes,
		MessageInfos:      file_opentelemetry_proto_metrics_v1_metrics_proto_msgTypes,
	}.Build()
	File_opentelemetry_proto_metrics_v1_metrics_proto = out.File
	file_opentelemetry_proto_metrics_v1_metrics_proto_goTypes = nil
	file_opentelemetry_proto_metrics_v1_metrics_proto_depIdxs = nil
}
